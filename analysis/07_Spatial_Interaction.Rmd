---
title: "Settlement Persistence Project, SBOM Script #7:"
subtitle: "Modeling Spatial Interactions"
author: "Rudolf Cesaretti"
date: "Last run on `r Sys.Date()`"
output:
  html_document:
    toc: true
    df_print: paged
    number_sections: true
bibliography: References.bib
csl: apa.csl
link-citations: yes
---


```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 300px;
}
```

```{r, setup, include=FALSE,echo=FALSE, message=FALSE,warning=FALSE}
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=75),tidy=TRUE)
#
rm(list = ls())
```

I do four things in this R markdown document: 

  3. Calculate settlement hierarchy metrics for AggSites at two spatial scales:
      + The global level (SBOM-region-wide) 
      + The local level (at a set radius surrounding each site)
  4. Reorganize the data and export for Script #7
  
  
# Setup 

All of the data and scripts are downloadable from the [new ASU SettlementPersist2022 github repository](https://https://github.com/rcesaret/ASUSettlementPersist2022), which can be downloaded locally as a .zip folder or cloned to your own account.

Either way, once you have done so, you will need to modify the working directory (setwd("C:/...)") path and "dir" variables in the code chunk below to match the repository location on your computer.

```{r, label='Set Local Directory Location', message=FALSE,warning=FALSE}

wd <- list()

#SET YOUR LOCAL DIRECTORY LOCATION HERE:
wd$dir <- "C:/Users/rcesaret/Dropbox (ASU)/ASUSettlementPersist2022/"
#wd$dir <- "C:/Users/TJ McMote/Dropbox (ASU)/ASUSettlementPersist2022"

wd$analysis <- paste0(wd$dir,"analysis/")
wd$data_r <- paste0(wd$dir,"data-raw/")
wd$data_p <- paste0(wd$dir,"data-processed/")
wd$data_f <- paste0(wd$dir,"data-final-outputs/")
wd$figs <- paste0(wd$dir,"figures/")
wd$funcs <- paste0(wd$dir,"functions/")

```


## Load R Packages and Custom Functions

```{r, label='Load Libraries', message=FALSE,warning=FALSE}
# Package names
packages <- c("rgdal", "rgeos", "sp", "sf", "GISTools", "raster", "Matrix", 
              "geodist", "gdistance", "lwgeom", "tidyverse", "tidyr", "pacman", 
              "data.table", "RColorBrewer", "cowplot", "stars", "ggnewscale", 
              "scales", "igraph", "tidygraph", "centiserve", "CINNA",
              "sfnetworks", "SpatialPosition", "lctools", "SpatialAcc", "mgcv",
              "gravity", "moin", "spflow", "simodels", "viridis", "broom", 
              "ggplotify", "ggiraphExtra", "modelsummary", "od", "minpack.lm", 
              "ggfortify", "mgcViz", "gratia", "modelsummary", "ggsn")#, "zoo", "ggrepel", "ggridges", "movecost"

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# load packages
invisible(lapply(packages, library, character.only = TRUE))

rm(packages,installed_packages)

#Read in custom R functions located in the wd$funcs directory folder
FUNCS <- list("splitByAttributes.R", "Radiation_EstFlows.R", "net_stats2.R", "si_to_od_dmat.R", "Est_Beta.R")#,  "SpInt_EstFlows.R"
invisible(lapply(FUNCS, function(x) source(paste0(wd$funcs,x))))
rm(FUNCS)

```



## Import Data

Data we are importing:

  1. the AggSite polygon data
  2. A simple polygon calculated in QGIS that specifies a hard outter border for the catchment areas of sites (constructed for sensitivity to survey borders and sites not included in the SBOM sample)
  3. Cost-distance matrices from script #3
  4. Least cost path rasters from script #3
  5. A raster hillshade basemap for the SBOM which includes the lakes

```{r, label='Import Data', message=FALSE,warning=FALSE}

#Agg Site and catchment polygon data
All_AggPoly <- readOGR(paste0(wd$data_p,"SBOM_AggSitePoly6.gpkg"))
All_CatchPoly <- readOGR(paste0(wd$data_p,"SBOM_CatchPoly6.gpkg"))
#reorder spatial polygons dataframes by period
All_AggPoly <- All_AggPoly[order(All_AggPoly$PeriodNum),]
All_CatchPoly <- All_CatchPoly[order(All_CatchPoly$PeriodNum),]

# Split polygons by Phase, saved as list of SPDFs
Poly_List <- splitByAttributes(spdata = All_AggPoly, attr = "Period", suffix="_SitePoly") 
Catch_List <- splitByAttributes(spdata = All_CatchPoly, attr = "Period", suffix="_CatchPoly") 

# convert spatial polygons dataframe to spatial points dataframe
#coor = All_AggPoly@data[,c("East","North")] #create separate dataframe of coordinates
#rownames(coor) <- as.numeric(rownames(coor)) #make sure rownames match
#All_AggPts <- SpatialPointsDataFrame(coor, All_AggPoly@data, match.ID = TRUE) #convert to points
#crs(All_AggPts) <- crs(All_CatchPoly) #set CRS
#All_AggPts = as(st_make_valid(st_as_sf(All_AggPts)), "Spatial") #make sure geometry is valid
#All_AggPts <- All_AggPts[order(All_AggPts$PeriodNum),]#reorder by period

# Split points by Phase, saved as list of spatial points dataframes
#Pts_List <- splitByAttributes(spdata = All_AggPts, attr = "Period", suffix="_Pts")

#Catchment boundary limit polygon
CatchLims <- readOGR(paste0(wd$data_r,"CatchLims.gpkg"))
CatchLims.sf = st_as_sf(CatchLims) #for ggplot 

## Hillshade Basemap Raster with lake
HillshadeLake <- raster(paste0(wd$data_r, "HillshadeLake.tif"))
HillshadeLake <- rast(HillshadeLake, crs = 26914)
Hillshade.s <- st_as_stars(HillshadeLake) #for ggplot basemap

#Cost-distance matrices
CD.mats <- readRDS(file=paste0(wd$data_p,"CDmats_list.RData"))
TrsprtNet_CDmatList <- readRDS(file=paste0(wd$data_p,"TrsprtNet_CDmatList.RData"))

TrsprtNet_lines_sfList <- readRDS(file=paste0(wd$data_p,"TrsprtNet_lines_sfList.RData"))
```


# Introduction

At this point, we have two major tasks left for the SBOM survey region trial analysis. **First**, we need to group the settlements of each modelling period into spatially-contiguous "urban (sub-)regions" or "settlement clusters." regional clusters are crucial to the analysis because they partition large datasets into valid groupings of integrated settlements, clarify statistical patterns in large datasets that would be swamped at the settlement-level, and delineate urban system structure/organization across space and time. By calculating (A) region-wide variables and (B) settlement-level variables in relation to regional values, we can calculate metrics that reflect regional differences for use in the final analysis. _This is undertaken in analysis #8._

**Second**, with this regional data in-hand, our ultimate goal is to use statistical models to predict settlement dynamics from all of the available data. In particular, we are interested in predicting persistence variables, growth rates and other time-series variables (regime shifts, regime characteristics, etc.) of individual settlements. _This is undertaken in analyses #9 and #10._

A critical step necessary for achieving both tasks is estimating the strength of social interaction among settlements across space and time. Urban system (sub-)regions are only valid insofar as they represent **_integrated_** groupings of **_systemically interdependent_** settlements. If "integration" is a group-level characteristic structured by pairwise interactions among settlements in various dimensions (e.g. socioeconomic, sociopolitical, etc.), then they must be operationally defined and measured by the relative magnitude of internal vs. external interactions. Aside from their importance for calculating regional metrics for settlements, we might also expect spatial interactions to be key variables in predicting settlement dynamics (i.e. persistance variables, growth rates, etc.)

_How do we estimate dimensional spatial interactions among settlements over time without settlement-level archaeological or historical data?_ While this might be achieved using the detailed artifact data available for certain regions like the US Southwest, the vast majority of cases in our world sample lack such data entirely.

Fortunately, **Spatial Interaction Models (SIMs)** provide a framework to resolve this dilemma. SIMs are quantitative models used to explain and predict flows of people, information or goods among a set of geographical locations. Since the 1950s and 60s, a growing body of SIM methodological innovations, empirical research and theoretical advances has made a huge impact on the development of several disciplines. In the context of international economics, SIM hypothesis testing has facilitated theoretical developments on the causes and prediction of trade flows [see e.g. @Head2014; @VanBergeijk2010]. In the context of geography, SIM analyses have been central to explaining and predicting patterned variation in human migration and transportation [see e.g. @Barbosa2018; @Erlander1990]. In the context of economic geography, SIM methods have revolutionized the theory building and analysis of land use, mobility, marketing, commodity flows and the geographical structure of production, markets and population  [see e.g. @Fotheringham1989; @Sen1995; @Wilson2000]. The effectiveness of SIMs in estimating and interpreting spatial flows is attested by their wide use not only in scientific research but policy making, urban/infrastructure planning and business strategy. 

Guided by these developments, the predictive power of SIMs makes them ideally-suited to modelling various dimensions of spatial interaction in archaeology. Indeed, SIMs are generic to human interactions in space -- independent of modern technology and social organization -- and therefore have also seen diffuse applications to historical and archaeological contexts [@Wilson2000; @Wilson2012; @Rihll1987; @Lovett1985; @Crymble2018; @Rivers2013; @Evans2012; @Bevan2013; @Evans2017; @Gauthier2021]. SIM empirical research and theory has demonstrated that different kinds of spatial flows are systematically related to different SIMs and predictor variables. Many of the relevant predictor variables necessary to estimate socioeconomic flows are already calculated in our dataset, and others can be proxied from theoretical relationships with our data. Moreover, as demonstrated in the following section, we can adapt published methods to calibrate SIMs, estimate parameters and predict flows _even in the absence of archaeological flow/interaction data_. 

In what follows, I methodically explain, justify and carry out SIM-based estimation of flows for the SBOM trial study dataset. First, I review the literature on SIMs in some detail in order to heuristically guide model selection and calibration. Next, I outline the proposed methods, operationalize interaction dimensions, derive expectations and calculate variables for the interaction/flow dimensions we want to model from the archaeological data. Finally, the proposed methods are implemented step-by-step in R to estimate pairwise interactions among settlements along different social dimensions for each modelling period using various R packages and custom-made functions.


# Background: Spatial Interaction Models (SIMs)

Spatial interaction modelling encompasses a flexible research paradigm aimed at explaining and predicting the structure of flows/interactions among populations of actors across space. In their most common form, SIMs model the volume of some specific directional flow (e.g. trade, migration, travel) as a function of

  1. push factors controlling the 'emmissiveness' or 'propulsiveness' of origin locations
  2. pull factors controlling the 'attractiveness' of destination locations
  3. the cost of overcoming the separation between origins and destinations (commonly expressed in terms of distance, money or time)
  
In their most general form, SIMs can thus be specified as
$$
\mathbf{T_{ij}} = f(V_i) \times f(W_j) \times f(\mathbf{C_{ij}})
$$
where

  * $\mathbf{T_{ij}}$ is an $n \times m$ matrix of flows between each $i$ of $n$ origins and each $j$ of $m$ destinations
  * $V_i$ is an $n \times p$ vector of $p$ origin attributes describing the emissiveness of origin $i$  
  * $W_j$ is an $m \times p$ vector of $p$ destination attributes describing the attractiveness of destination $j$  
  * $\mathbf{C_{ij}}$ is an $n \times m$ matrix of the costs (usually distance or time) to overcome the physical separation between each $i$ of $n$ origins and each $j$ of $m$ destinations
  
As such, the core formulation of a SIM involves some set of flows/interactions being predicted by the product of functions for origin emissiveness, destination attractiveness and spatial deterrence (distance decay). Each of these can be represented by one or more variables. The flows/interactions being modeled could be anything -- from highly specific (e.g. attendance at an academic conference) to extremely general (e.g. telephone calls). The choice of predictor variables is of course contingent on the kind of flows being modeled (discussed in the following sections), a sample of which are offered for common dimensions in the table below taken from [@OshanND].

**Table taken directly from [@OshanND]**
```{r, 'Oshan n.d. SIM Table', echo=FALSE, out.width = '100%'}
knitr::include_graphics(paste0(wd$figs,"OshanSIMtab.png"), FALSE)
```
 
The figure below, taken from Oshan [-@OshanND], nicely illustrates the basic framework. As a network of spatial flows, interactions can be represented as origin-destination ('O-D') matrices equivalent to a network adjacency matrix. Origin nodes and destination nodes need not be the same, and are sometimes completely different in certain contexts. SIMs can be used to analyze both directed and undirected (symmetrical) flows at any internally-consistent level of spatial aggregation / scale. SIMs are most commonly used used to analyze stationary flow/interaction patterns over time intervals not time that do not undergo significant structural changes [@Sen1995]. As such, these periods are understood as short-term equilibria like those postulated by canonical models of economic geography [e.g. @Alonso1964; @Muth1969; @Mills1967; @vonThunen1910; @Hotelling1929; @Christaller1933; @Losch1940; @Weber1909]. While dynamic applications of SIMs do exist, structural changes over time are most commonly addressed by comparing the SIM results of static periods.

**Figure taken directly from [@OshanND]**
```{r, 'Oshan n.d. SIM Figure', echo=FALSE, out.width = '100%'}
knitr::include_graphics(paste0(wd$figs,"OshanSIMfig.png"), FALSE)
```

In general, researchers generally use SIMs to analyze a spatial dataset comprised of locational attributes and observed flows among a set of origin and destination locales. After specifying the model and its variables, the model is then calibrated using multiple regression -- predicting the observed flows from the specified SIM by estimating parameter values. These topics are covered in section 3.1 and 3.2. In section 3.3, I cover the use of SIMs in archaeology, with specific focus on how SIMs can be specified and calibrated in the absence of observed flow data.


## Modelling Framework

Since the integrative synthesis of Wilson [-@Wilson1970; -@Wilson1971], SIMs have often been described as a “family of models” that share a common framework. The common framework of this family is the so-called ‘gravity model’ of spatial interaction that crystallized in economic geography during the the 1940s and 50s [e.g. @Carrothers1956; @Olsson1965; @Isard1960; @Stewart1941, @Zipf1946; @Dodd1950]. The gravity model shares its basic mathematical form with Newtonian gravitation, thus modelling interactions between human populations in analogy to the gravitational force attracting two masses. The classic gravity model is given by the equation
$$
I_{ij}=\frac{P_i P_j}{d_{ij}^2}=P_iP_jd_{ij}^{-2}
$$
where $I$ is some interaction or flow from origin $i$ to destination $j$, $P_i$ and $P_j$ are their respective populations and $d_{ij}$ is the distance between them.


### Generalized Gravity Model (or 'Unconstrained' SIM)

Subsequent refinements of the classical gravity model have given way to a 'generalized gravity model.' Using a new notation system, this generalized gravity model takes the form
$$\mathbf{T_{ij}} = k V_i^{\mu} W_j^{\alpha} f(\mathbf{C_{ij}})$$
where

  * $\mathbf{T_{ij}}$ is an $n \times m$ matrix of flows between each $i$ of $n$ origins and each $j$ of $m$ destinations
  * $V_i$ is an $n \times p$ vector of $p$ origin attributes describing the emissiveness of origin $i$  
  * $W_j$ is an $m \times p$ vector of $p$ destination attributes describing the attractiveness of destination $j$  
  * $\mathbf{C_{ij}}$ is an $n \times m$ matrix of the costs (usually distance or time) to overcome the physical separation between each $i$ of $n$ origins and each $j$ of $m$
  * $\mu$ is a $p \times 1$ vector of parameters representing the effect of $p$ origin attributes on flows
  * $\alpha$ is a $p \times 1$ vector of parameters representing the effect of $p$ destination attributes on flows
  * $k$ is a constant scaling factor to ensure the total observed and predicted flows are consistent
  
It should be noted that different scholars and disciplines have employed a wide range of different variable names and notations for SIMs. Those employed here (for the most part) follow the increasingly standardized notation of geography and economic geography [see e.g. @Wilson1970; @Fotheringham1989; @Sen1995].

The additions of the generalized model are subtle but important. First, the model can now incorporate multiple origin and destination attributes as necessary. Second, the addition of parameters $\mu$ and $\alpha$ give the model flexibility with respect to the influence of each origin and destination attribute on flows. Third, distance $d_{ij}$ is replaced by a cointextually operationalized cost-distance $\mathbf{C_{ij}}$ (which can still use geographical distance as a proxy for cost-distance). Fourth, whereas the classical model directly specifies an inverse distance squared 'distance decay' function (also known as a 'deterrence' function), the generalized model is agnostic to its appropriate form (As explained in the following section, distance decay functions can take a wide range of forms specific to particular contexts). Finally, the addition of the constant parameter $k$ makes sure that the global total number of predicted flows is the same as the the global total number of observed flows.


### Wilson's "Family of Models"

Building on this foundation, Wilson's [-@Wilson1970; -@Wilson1971] watershed "family" of SIMs introduced three new variants of the generalized gravity model that form the foundation of the contemporary SIM framework in [economic] geography. These variants differ from the generalized gravity model by introducing further constraints to ensure that the number of predicted flows match the number of observed flows **_at the level of each origin/destination_**. While parameter $k$ in the generalized gravity model does this at the _global level_, the flows to and from each origin/destination locale predicted by the generalized gravity model may vary (sometimes considerably) from the observed flows. By introducing balancing factors for individual origin/destination locales, Wilson's [-@Wilson1970; -@Wilson1971] variants are able to preseve the locally observed flow frequencies in the flows predicted by the SIM. The generalized gravity model is thus often referred to as the "unconstrained model" in Wilson's four variant a "family of models:"

  1. Generalized gravity model (or 'Unconstrained' model)
  2. Production-constrained -- where out-flows are constrained by banancing factors, but in-flows are not
  3. Attraction-constrained -- where in-flows are constrained by banancing factors, but out-flows are not
  4. Production-Attraction-constrained (or ‘Doubly-constrained’) -- where both in-flows and out-flows are constrained by banancing factors
  
The latter three constrained variants of Wilson [-@Wilson1970; -@Wilson1971] are specified (in generalized form) as follows:

Production-constrained:
$$\mathbf{T_{ij}} = A_i O_i W_j^{\alpha} f(\mathbf{C_{ij}}) \\ A_i = \left( \sum_{j=1}^{n} W_j^{\alpha} f(\mathbf{C_{ij}}) \right)^{-1}$$
Attraction-constrained:
$$\mathbf{T_{ij}} = B_j D_j V_i^{\mu} f(\mathbf{C_{ij}}) \\ B_j = \left( \sum_{i=1}^{m} V_i^{\mu} f(\mathbf{C_{ij}}) \right)^{-1}$$
Doubly-constrained SIM:
$$\mathbf{T_{ij}} = A_i B_j O_i D_j f(\mathbf{C_{ij}}) \\ A_i = \left( \sum_{j=1}^{n} W_j^{\alpha} f(\mathbf{C_{ij}}) \right)^{-1} \\ B_j = \left( \sum_{i=1}^{m} V_i^{\mu} f(\mathbf{C_{ij}}) \right)^{-1}$$
where

  * $O_i$ is an $n \times 1$ vector of the total number of flows emanating from origin $i$  
  * $D_j$ is an $m \times 1$ vector of the total number of flows terminating at destination $j$  
  * $A_i$ is an $n \times 1$ vector of the origin balancing factors that ensures the total out-flows are preserved in the predicted flows
  * $B_j$ is an $m \times 1$ vector of the destination balancing factors that ensures the total in-flows are preserved in the predicted flows


Discuss balancing factors / constraints and their estimation




employ entropy maximization constraints derived from statistical mechanics and information theory [@Wilson1970].







Each of these different models excels at answering different research questions in different contexts.














@OshanND
@Dennett2018
@Oshan2021
@Berry1967
@Batty2010
@Oshan2016
@Wilson1971
@Wilson1998
@Isard1998
@Wilson2000
@Wilson2013
@Sen1995
@Fotheringham1989
@Dennett2013







### Distance Decay Functions











Power:
$$
f(\mathbf{C_{ij}})=\mathbf{C_{ij}}^{-\beta}=\frac{1}{\mathbf{C_{ij}}^{\beta}}
$$





where 
  * $\beta$ is a parameter representing the impact of movement costs on flows.
  
  



shifted power-deterrence function
$$
f(\mathbf{C_{ij}})=\mathbf{(\epsilon +C_{ij})}^{-\beta}
$$


Champernowne POWER deterrence function.
$$
f(\mathbf{C_{ij}})=\mathbf{[\epsilon +(C_{ij})^\beta]}^{-1}
$$



Exponential:
$$
f(\mathbf{C_{ij}})=e~^{-\beta~\mathbf{C_{ij}}} =\frac{1}{e~^{\beta~\mathbf{C_{ij}}}}
$$

Two-Parameter Exponential:
$$
f(\mathbf{C_{ij}})=\alpha~e~^{-\beta~\mathbf{C_{ij}}} 
$$




Two-Parameter Exponential:
$$
f(\mathbf{C_{ij}})=\alpha~e~^{-\beta~\mathbf{C_{ij}}} 
$$

exponential-square root decay function:
$$
f(\mathbf{C_{ij}})=e~^{-\beta~\sqrt{\mathbf{C_{ij}}}}  
$$
https://journals.sagepub.com/doi/pdf/10.1177/0160017610387296
Accessibility and Impedance Forms- Empirical Applications to the German Commuting Network


```{r, 'Fotheringham & O'Kelly 1989 Decay Chart', echo=FALSE, out.width = '100%'}
knitr::include_graphics(paste0(wd$figs,"FotheringhamDecay.png"), FALSE)
```


Tanner Function:
$$
f(\mathbf{C_{ij}})= \mathbf{C_{ij}}^{-\alpha}~e~^{-\beta~\mathbf{C_{ij}}} 
$$

Shifted Tanner Function:
$$
f(\mathbf{C_{ij}})= ( \epsilon + \mathbf{C_{ij}})^{-\alpha}~e~^{-\beta~\mathbf{C_{ij}}} 
$$


Gamma Function:
$$
f(\mathbf{C_{ij}})= \mathbf{C_{ij}}^{\alpha}~e~^{-\beta~\mathbf{C_{ij}}} 
$$


Shifted Gamma Function:
$$
f(\mathbf{C_{ij}})= ( \epsilon + \mathbf{C_{ij}})^{\alpha}~e~^{-\beta~\mathbf{C_{ij}}} 
$$
Gaussian decay function: 
$$
f(\mathbf{C_{ij}})=e~^{-\beta~{\mathbf{C_{ij}}}^2} 
$$
Accessibility and Impedance Forms: Empirical Applications to the German Commuting Network
https://journals.sagepub.com/doi/pdf/10.1177/0160017610387296

Modified Gaussian:
$$
f(\mathbf{C_{ij}})=e~^{-{\mathbf{C_{ij}}}^2/\beta~} 
$$
https://findingspress.org/article/8416-accessibility-toolbox-for-r-and-arcgis?attachment_id=21364

Log-normal decay function
$$
f(\mathbf{C_{ij}})=e~^{-\beta~(\mathrm{log}{\mathbf{C_{ij}}})^2}  
$$
Accessibility and Impedance Forms: Empirical Applications to the German Commuting Network


Logistic:
$$
f(\mathbf{C_{ij}})= \frac{1}{1+e~^{-\beta~(\mathbf{C_{ij}}-\alpha)}}=\frac{e~^{\beta~(\mathbf{C_{ij}}-\alpha)}}{1+e~^{\beta~(\mathbf{C_{ij}}-\alpha)}}
$$


Sigmoidal:
$$
f(\mathbf{C_{ij}})= \frac{1}{(1+(\mathbf{C_{ij}}/D)^\alpha)^{\gamma}}
$$

### The Spatial Structure of Intervening Opportunities




### Radiation Model

https://covid-19-mobility-data-network.github.io/mobility/articles/V5_list_models.html

This model was created explicitly as an alternative to various gravity models and, in certain cases, was demonstrated to generate improved empirical predictions of human population movement between origins and destinations. This model shares some basic features with gravity models but importantly, the approach includes no parameters at all. Instead, this model uses simply measures of population at a set of sites and the distances between them. 

Model of socioeconomic spatial interaction 

  * commuting to work
  * migrating (changing residence and employment)
  * All travel (incl. shopping trips, business and recreation)
  * communication (cell phone calls)
  * trade

This model is inspired by a diffusion model where each individual living in an unit i has a certain probability of being “absorbed” by another unit j according to the spatial distribution of socioeconomic opportunities. The original radiation model is free of parameters and, therefore, it does not require calibration. The conditional interaction (radiation/absorbtion) probability is
$$
\mathrm{P}(1 \mid m_i, m_j, s_{ij}) = \frac{m_in_j}{(m_i + s_{ij})(m_i + n_j + s_{ij})} 
$$
where $m_i$ is the origin population, $n_j$ is the destination population, and $s_{ij}$ is the total population of all other competing destinations within a circle centered at origin $i$ whose radius is the distance between origin $i$ and destination $j$. 

This generalized probability of interaction is then parameterized by the scalar $T_i$, representing the magnitude of all outgoing 'interactions' in some dimension (e.g. commuters, travelers, migrants, etc.), to obtain the estimated total directional flow from origin $i$ to destination $j$, $T_{ij}$, given by
$$
T_{ij} = T_i \frac{m_in_j}{(m_i + s_{ij})(m_i + n_j + s_{ij})}
$$
Of course, the magnitude of $T_i$ is empirically variable by dimension and locale, but is necessarily proportional to the population $m_i$ of origin $i$. Their analysis suggested that most dimensions were proportional to population (phone data and freight transportation were not due to sampling bias), and, critically, that they were independent of both the spatial density of employment and the spatial cost-benefit distribution of employment. Simini et al. [-@Simini2012] therefore suggest that the variability of $T_i$ is scale invariant, such that
$$
T_{ij} =\gamma m_i\frac{m_in_j}{(m_i + s_{ij})(m_i + n_j + s_{ij})} \propto \frac{m_i^2 n_j}{(m_i + s_{ij})(m_i + n_j + s_{ij})}
$$
where $\gamma$, the local fraction of outgoing interactions, as the only unknown parameter. Given their assertion that this is stochastic, dimensional, scale-invariant, and independent of intervening employment opportunity, population can be used as a proxy. As such, the model becomes parameter-free since the spatial interaction flux probability is not dependent on $\gamma$.

Since its publication, further tests and analyses have led to revisions/adaptations of the model. 
Masucci et al. [-@Masucci2013] analyze different data suggesting that $T_i = \gamma m_i$ is in fact scale dependent, changing the model to
$$
T_{ij} = \frac{T_i}{1-\frac{m_i}{M}} \frac{m_in_j}{(m_i + s_{ij})(m_i + n_j + s_{ij})}
$$
where $M$ is the origin's fraction of total regional population. Indeed, such a gravitational size effect is to be expected theoretically given ubiquitous conditions of spatial heterogeneity, increasing returns to scale in urban agglomeration effects, and heavily right-skew city size distributions [@Masucci2013].

Other analysts have demonstrated that the radiation model greatly underperforms exponential gravity models at smaller spatial scales [@Lenormand2012; @Liang2013]. While the radiation model achieves the best predictions at long distances, these flows are much lower volume and a small fraction of the total [@Lenormand2016]. To account for this, the original authors [@Yang2014] propose an extended radiation model with the flux probability given by
$$
\mathrm{P}(1 \mid m_i, m_j, s_{ij}) = \frac{[(m_i+n_j+s_{ij})^\alpha - (m_i+s_{ij})^\alpha]~(m_i^\alpha+1)}{[(m_i + s_{ij})^\alpha+1]~~[(m_i + n_j + s_{ij})^\alpha+1]}
$$
where the new parameter, $\alpha$, models the impact of rival employment opportunities between origin and destination. To calibrate the $\alpha$ parameter in the absence of data, Yang et al. [-@Yang2014] follow gravity model methods to propose $\alpha$ as proportional to the average commuting distance, $l$, assumed to be the radius of the average area of the spatial units of analysis (census tracts). This makes $l= \sqrt{A} $, which enabled them to estimate from empirical data the average value of alpha as $\alpha=0.0085~l^{1.33} $. For the modern data, MSA-scale values of $\alpha$ ranged between 0 and 2. 



## Calibration Framework

Regression is perhaps the most frequently used calibration method due to its flexibility


linear programming and non-linear optimization are also possible (i.e., Wilson & Senior, 1974; Batty
& Mackie, 1972).

Equation (2) can be linearized by taking the logarithm of both sides, yielding the
so-called log-linear gravity model,
$$
\mathrm{log_e}(\mathbf{T_{ij}}) = k + \mu~\mathrm{log_e}(V_i) + \alpha~\mathrm{log_e}(W_j) + \beta~\mathrm{log_e}(\mathbf{C_{ij}})
$$
which can be expressed more generally as a log-normal regression specification and included within
an ordinary least-squares regression specification as
$$
\mathrm{log_e}(\mathbf{T_{ij}}) = k + \mu~\mathrm{log_e}(V_i) + \alpha~\mathrm{log_e}(W_j) + \beta~\mathrm{log_e}(\mathbf{C_{ij}})+\epsilon_{ij}
$$
where $\epsilon$ is a normally distributed error term with a mean of 0

However, a Poisson regression specification was proposed for the family of SI models
over ordinary least squares regression because flows are often counts of people or objects and should
be modeled as discrete entities and Poisson regression avoids the potential issue of taking the
logarithm of zero-valued flows (Flowerdew & Aitkin, 1982; Flowerdew & Lovett, 1988;
Fotheringham & O’Kelly, 1989; Silva & Tenreyro 2006; Farmer & Oshan, 2017). Another advantage
of Poisson regression is that adding origin fixed effects and/or destination fixed effects (i.e., binary
indicators or dummy variables) achieves the same objective as the balancing factors 𝐴! and/or 𝐵" in
equations (4-6) to uphold the desired constraints (Tiefelsdorf & Boots, 1995).

Poisson log-linear regression calibration framework
is also popular because it more realistically
models discrete entities (i.e. flows of
people), avoids the issue of zero flows that cannot
be logged, and is not subject to transformation
bias for the dependent variable (Flowerdew
and Aitkin, 1982; Flowerdew and Lovett, 1988).
Using binary indicator variables for each origin
and/or destination within Poisson regression
yields the constrained variants of the family of
SI models, producing results equivalent to those
obtained using nonlinear optimization (Tiefelsdorf
and Boots, 1995).


The parameters for all models in the family are estimated from empirical data using some form of linear regression—usually maximum likelihood estimators (MLE) specifying parametric distributions matching the data. Maximum entropy constraints are usually fitted using either Lagrange multipliers or equivalent numerical search/convergence algorithms

### Calibrating SIMs in R


[@Kalogirou2020]
[@SpatialAcc]
SpatialAcc: Spatial Accessibility Measures
http://lctools.science/ = lctools+SpatialAcc+SpatialML

[@SpatialPosition]
https://cran.r-project.org/web/packages/SpatialPosition/index.html
https://cran.r-project.org/web/packages/SpatialPosition/vignettes/SpatialPosition.html

[@spflow]
https://github.com/LukeCe/spflow
https://lukece.github.io/spflow/articles/paris_commute_flows.html
https://cloud.r-project.org/web/packages/spflow/index.html
devtools::install_github("LukeCe/spflow")
https://www.tse-fr.eu/fr/publications/revisiting-estimation-methods-spatial-econometric-interaction-models
https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9787.2008.00573.x

[@gravity]
https://cran.r-project.org/web/packages/gravity/index.html


[@simodels]
[@od]
https://cran.r-project.org/web/packages/simodels/index.html
https://robinlovelace.github.io/simodels/articles/sims-first-principles.html
https://cloud.r-project.org/web/packages/simodels/vignettes/sims-first-principles.html
https://github.com/Robinlovelace/simodels
https://robinlovelace.github.io/simodels/


https://github.com/COVID-19-Mobility-Data-Network/mobility/
devtools::install_github('COVID-19-Mobility-Data-Network/mobility')
https://covid-19-mobility-data-network.github.io/mobility/index.html



[@moin]

https://gitlab.com/CRC1266-A2/moin/-/tree/master
devtools::install_git("https://gitlab.com/CRC1266-A2/moin")
https://rdrr.io/github/CRC1266-A2/moin/f/
https://github.com/juhly/moin/blob/master/README.md
https://github.com/juhly/moin
devtools::install_github("CRC1266-A2/moin")



Crymble, A. (2019). Introduction to Gravity Models of Migration & Trade.
Programming Historian.
https://programminghistorian.org/en/lessons/gravity-model


Siah, J. (2018). RPubs—Lab 10: Spatial Interaction Modeling in R.
https://rpubs.com/Striker/makingmaps_lab10



Dennett, A. (2012). Estimating flows between geographical locations:‘get me started
in’spatial interaction modelling (Working Paper No. 184; CASA Working Paper
Series). Citeseer.

Dennett, A. (2018). Modelling population flows using spatial interaction models.
http://minerva-access.unimelb.edu.au/handle/11343/233564

https://github.com/adamdennett/LondonSchoolsSIM
https://github.com/adamdennett/SIModelling
https://rpubs.com/adam_dennett/257231
https://rpubs.com/adam_dennett/259068
https://rpubs.com/adam_dennett/376877

https://findingspress.org/article/8416-accessibility-toolbox-for-r-and-arcgis?attachment_id=21364
https://github.com/higgicd/Accessibility_Toolbox
https://github.com/atfutures/dodgr


### Theory and Interpretation

Most current approaches to SIMs see the aggregate flows being modelled as complex systems -- emergent system-level structures produced by diverse but constrained micro-level behaviors [@Wilson2000]. At the micro-level, the constraints producing the emergent system structure are grounded in a decision process where actors face a trade-off between the costs and benefits of interaction with a set of competing destinations [@Fotheringham1989]. Due to the diversity of contexts, preferences and constraints of specific actors, these micro-level behaviors are averse to prediction and strong deterministic regularities. However, at the macro-level, strong patterns do emerge. As such, researchers have tended to adopt a probablistic framework focusing on explicit modeling of macro-level structures as statistical averages/trends produced by the overall distribution of actor decisions and constraints [@Sen1995]. SIMs are therefore best suited to macro-level research questions regarding the spatial structure of systems.

In this context, the statistical frameworks used to estimate SIMs 

In the context of statistical modeling, maximum entropy methods provide a systematic way to model general patterns from a sample of idiosyncratic data using the fewest possible assumptions. The principle of maximum entropy can be thought of as an approach to statistical modeling that takes a conservative epistemological position on the problem of overfitting. The degree to which a statistical model should fit the data depends on whether the research question addresses the particular occurrence(s) represented in the data, or whether you’re treating the data as a representative sample of some wider phenomenon. ‘Overfitting’ usually involves using an overly complex model to explain patterns in the data that are idiosyncratic to the sample (i.e. caused by sampling error or other selection biases). This is a minor problem when comparing or testing hypotheses about the specific empirical cases represented by a dataset. A close fit between model and data enables us to make arguments about what caused the data—either that a theoretical model explains the observed reality, or that a statistical model accurately characterizes the relationship between the observed variables. In such cases, we want statistical models to explain most of the variability in the observed data, and the model complexity threshold of overfitting is often intuitively-clear. 

But problems arise when using a sample with some unknown degree of error to address the more general processes that produced them. Say for example you wanted to estimate patterns across a region, but you only have data from a sample of subregions. Extrapolating this data imposes the idiosyncrasies of specific locales on the rest of the region. This is textbook overfitting. One common way of dealing with this problem is to use complex statistical models to estimate trends in the unknown data using other variables known to covary with the patterns in question. Yet this kind of predictive modeling necessitates the specification of highly-specific quantitative assumptions from a large number of alternatives. Without more data to evaluate model specifications, choosing the ‘right’ specifications involves some degree arbitrariness and uncertainty. While these predictive models can have great power and utility, the risk of overfitting is high.
What maximum entropy provides is a systematic method to model general patterns from a sample of idiosyncratic data using the fewest possible assumptions. 
Not just a means of modelling missing or unknown data, but also as a kind of null model 

This difference can be thought of in terms of probability. Should we treat a specific outcome as highly probable, or is it important to think of it as merely one possible instantiation of many? This distinction is fundamental to the epistemology of the historical sciences, where we often debate about the degree to which particular historical events were caused by broader systemic forces or idiosyncratic historical contingencies.




## SIMs in Archaeology



### Calibrating SIMs in the absence of flow data

-blah blah
-blah blah

@Rivers2013
@Evans2012
@Bevan2013
@Evans2017
@Brughmans_Peeples_2022
@Peeples_Brughmans_2022
@Rihll1987
@Gauthier2021
Gauthier poster and GitHub
@moin

Citations for simulations



# Proposed Methods

Model different theoretical dimensions of interaction
--using well-established covariates and proxies
--using high-performing models 

## Dimensions of Interaction

--retail + urban services (Production-constrained); proxy for emissiveness?? == market integration
--AG trade (Attraction-constrained) = urban demand; AG supply surplus
--commodity flows (radiation) --> commuters as a function of prior two SIMs node stats and accessibility(pop^1.2); accessibility(pop^1.2)= m and n
--migration (doubly constrained) see excel sheet








spatial interaction inexorably linked with economic development through the process of specialization
---Smithian growth
very low levels of economic development of div of labor = high self sufficiency = low levels of spatial interaction
Smithian growth --> increased specialization --> productivity = scale, extent and integration of market = trade and communication
at the lower level, learning by doing = 

Smithian growth is intimately connected to the origins
of agglomeration effects. At the macro-level, specialization is driven by the growth of markets and
demand (Kelly 1997; Persson 2010). But at the microlevel, specialization is driven by “learning by doing”–
the generation of specialized knowledge that enables
production to be focused on increasingly specific outputs. This involves imitating and learning from others,
refining processes, streamlining logistics, and innovating production practices (Arrow 1962; Solow 1997).
Agglomeration effects are a catalyst of learning by
doing. Whereas Smithian growth involves learning by
doing within a formal occupation, agglomeration
effects enhance the flow of information and skills
among them. Agglomeration effects produce a feedback that diffuse specialized knowledge throughout
the local network of individuals, firms, and institutions. Urban agglomeration economies are thus a
non-market-mediated catalyst of Smithian growth,
and the result of this Smithian-Agglomeration positive
feedback is IRS (Bettencourt 2013; Bettencourt,
Samaniego, and Youn 2014; Fujita, Krugman, and
Venables 1999; Lobo et al. 2013).

spatial interaction = scale, extent and integration of market


Fotheringham --> migration section; migration and economic development

Fotheringham --> retail section; economic development?


### Sociopolitical Institutions

-Production-constrained SIM
--attractiveness = f(settlement hierarchy level, population, urban population)
----difference in; calculated in od dataframe! 
--emissiveness = f(settlement hierarchy level, population, urban population)

THIS IS NOT SOCIOPOLITICAL CONTROL OR POLITY!!
--this is integration with hierarchical social-political-cultural-juridicial-administrative-governance institutions
--these are hierarchical --> integration with closer centers with DIVERGENT VALUE
--Attractiveness = abs(pop_i*SettHeirLevel_i - pop_j*SettHeirLevel_j)
--Emissiveness = pop_i*SettHeirLevel_i



### Agricultural Flows

-Production-constrained SIM
--attractiveness = f(Catch_Popdens, population, urban population, PopPressure, PopPressureNW, Catch_Popdens)
--emissiveness = f(Catchment_ha, CatchmentBeyond_ha, AGPot.tot, AGPot.avg, AGPotNW.tot, AGPotNW.avg, population, Catch_Popdens)

attractiveness = population + urbPop^1.2 * PopPressure
emissiveness = AG surplus = AG Production - AG Consumption = 
          (Catch_Popdens / pop ??) AGPot.avg * Catchment_ha - pop


### Socioeconomic Flows
-Radiation Model and/or Production-constrained SIM
-max of two models, divided by rowsum??
--attractiveness = f(settlement hierarchy level, population, urban population, pop/urban accessibility, urbaniz ratio, transport net centrality)
----difference in EZ.avg; calculated in od dataframe! 
--emissiveness = f(settlement hierarchy level, population, urban population, pop/urban accessibility, urbaniz ratio, transport net centrality)
----difference in EZ.avg; calculated in od dataframe! 

attractiveness =  (abs(Ez.avg_i - Ez.avg_i)+1)* [accessibility(pop^1.2) OR pop^1.2]
emissiveness = pop^1.2







Radiation Model 
--to model the distance decay function for different spatial interactions



https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html


## Radiation Models

### Background






We have defined a function for calculating radiation among a set of sites using just two inputs:

* **`pop`** is a vector of population values.
* **`d_mat`** is a distance matrix among all nodes.


```{r, "radiation model symmetry", eval=FALSE, echo=F, message=FALSE, warning=FALSE}

#test to check the degree of symmetry

test = Radiation_EstFlows(df = Poly_List[[1]]@data,var = "Population.s2",
                       d_mat = TrsprtNet_CDmatList[[1]],xcoords = Poly_List[[1]]@data$East,
                       ycoords = Poly_List[[1]]@data$North,crs_coords = 26914,
                       scale = "none",commuters = "none",outputs = "adjmat")
test[["adjmat"]] - t(test[["adjmat"]])
test[["adjmat"]] / t(test[["adjmat"]])
test[["adjmat"]] + t(test[["adjmat"]])

```

Not at all symmetrical

when NOT using conditional probs (i.e. using actual parameterized flows)
you could add the matrix of flows to its transpose to create the 
total (undirected) volume of pairwise flows


```{r, "compare radiation model results w/ different params", eval=FALSE, echo=F, message=FALSE, warning=FALSE}

df = Poly_List[[5]]@data
var = "Population.s2"
d_mat = TrsprtNet_CDmatList[[5]]
xc=Poly_List[[5]]@data$East
yc=Poly_List[[5]]@data$North
crsc=26914

rad_orig_prob = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=F,scale="none", 
                          commuters="none",outputs ="sflines")
rad_orig_invar = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=F,scale="invariant", 
                          commuters="var",outputs ="sflines")
rad_orig_var = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=F,scale="variant", 
                          commuters="var",outputs ="sflines")
rad_ext_invar_a0.5 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=T,scale="invariant", alpha=0.5,
                          commuters="var",outputs ="sflines")
rad_ext_invar_a2 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=T,scale="invariant", alpha=2,
                          commuters="var",outputs ="sflines")
rad_ext_var_a0.5 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=T,scale="variant", alpha=0.5,
                          commuters="var",outputs ="sflines")
rad_ext_var_a2 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=T,scale="variant", alpha=2,
                          commuters="var",outputs ="sflines")

modeldf = st_drop_geometry(rad_orig_invar[[1]][,1:9])
modeldf$orig_invar_P <- as.numeric(unlist(st_drop_geometry(rad_orig_invar[[1]][,10])))
modeldf$orig_invar_Tij <- as.numeric(unlist(st_drop_geometry(rad_orig_invar[[1]][,11])))
modeldf$orig_var_P <- as.numeric(unlist(st_drop_geometry(rad_orig_var[[1]][,10])))
modeldf$orig_var_Tij <- as.numeric(unlist(st_drop_geometry(rad_orig_var[[1]][,11])))
modeldf$ext_invar_a0.5_P <- as.numeric(unlist(st_drop_geometry(rad_ext_invar_a0.5[[1]][,10])))
modeldf$ext_invar_a0.5_Tij <- as.numeric(unlist(st_drop_geometry(rad_ext_invar_a0.5[[1]][,11])))
modeldf$ext_invar_a2_P <- as.numeric(unlist(st_drop_geometry(rad_ext_invar_a2[[1]][,10])))
modeldf$ext_invar_a2_Tij <- as.numeric(unlist(st_drop_geometry(rad_ext_invar_a2[[1]][,11])))
modeldf$ext_var_a0.5_P <- as.numeric(unlist(st_drop_geometry(rad_ext_var_a0.5[[1]][,10])))
modeldf$ext_var_a0.5_Tij <- as.numeric(unlist(st_drop_geometry(rad_ext_var_a0.5[[1]][,11])))
modeldf$ext_var_a2_P <- as.numeric(unlist(st_drop_geometry(rad_ext_var_a2[[1]][,10])))
modeldf$ext_var_a2_Tij <- as.numeric(unlist(st_drop_geometry(rad_ext_var_a2[[1]][,11])))
modeldf$orig_invar_Tij_pct <- modeldf$orig_invar_Tij/modeldf$m
modeldf$orig_var_Tij_pct <- modeldf$orig_var_Tij/modeldf$m
modeldf$ext_invar_a0.5_Tij_pct <- modeldf$ext_invar_a0.5_Tij/modeldf$m
modeldf$ext_invar_a2_Tij_pct <- modeldf$ext_invar_a2_Tij/modeldf$m
modeldf$ext_var_a0.5_Tij_pct <- modeldf$ext_var_a0.5_Tij/modeldf$m
modeldf$ext_var_a2_Tij_pct <- modeldf$ext_var_a2_Tij/modeldf$m

colnames(modeldf) <- c("from","to","r_ij","m","n","Ti","self","s","n_s","orig_invar_P",
"orig_invar_Tij","orig_var_P","orig_var_Tij","ext_invar_a0.5_P","ext_invar_a0.5_Tij",
"ext_invar_a2_P","ext_invar_a2_Tij","ext_var_a0.5_P","ext_var_a0.5_Tij","ext_var_a2_P",
"ext_var_a2_Tij")

library(psych)

x=as.data.frame(modeldf[,c(11,13,15,17,19,21,22:27)])

pairs.panels(x, gap = 0,pch=21)

xx=as.data.frame(modeldf[,c(10,12,14,16,18,20,22:27)])

pairs.panels(xx, gap = 0,pch=21)

xxx=as.data.frame(modeldf[,c(10:13,22:23)])

pairs.panels(xxx, gap = 0,pch=21)

detach("package:psych", unload = TRUE)

ggplot(data = modeldf,aes(y = ext_invar_a0.5_P, x = r_ij, color=ext_invar_a2_P, size=n)) +
  geom_point() +
  labs(y = "ext_invar_a0.5_P", x = "r_ij")+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))

```

  * lower alpha exponents = faster rate of distance decay in flow strength for short distances
  * higher alpha exponents = slow rate of dist decay at short distances with steep falloff for long distances
  * Not much difference between the scale variant + invariant models
  * some but not huge difference between original and extended models BECAUSE the dominant factor controlling interaction strength is the sizes of the origin and destination!! Small settlements have few people to send!!
  
  
## ???

Radiation model doesnt require parameter fitting, and provides a good fit for flows empirically

We can use radiation model outputs to estimate likely/reasonable parameters for distance decay using exponential and power functions

Use radiation model conditional probabilities rather than estimated flows because
  * this isolates the distance decay of the model the most
  * conditional probabilities already take into account relative size + Intervening opportunities (=dist decay in the radiation model)
  * dont cloud interaction flows with further size effects, which swamp the distribution


Illustrative to compare radiation model outputs to fitted exponential and power functions across model types and parameters (original vs extended; alpha values)
  * shows us how the radiation model changes under different model types and parameters (original vs extended; alpha values)
  * shows us how using exponential and power functions would yield a divergent model of interaction flows
  
We can then in-turn use these heuristics to select optimal decay functions and parameter values for our different interaction dimensions from theoretical expectations about the impact of cost-distance on those dimensions

Units are hrs; rule of thumb 5km/hr rough average; so 1 hr = e^0 hrs ~= 5km 



DO THESE NEED TO BE ESTIMATED WITH THE ACTUAL PROXY FLOWS INSTEAD???
--YOU SHOULD AT LEAST SEE HOW MUCH IT CHANGES THE SLOPE+INTERCEPT....
  * NEED TO MODIFY Radiation_EstFlows.R to take separate m, n and T_i params AND in calculations..
  * Est_Beta.R throughout to take something other than conditional probs = m+n+TI inputs
  * poisson regression
  * calculate input variables

```{r, "compare radiation model distance decay across parameters", message=FALSE, warning=FALSE}

p=5

tmp1 <- Est_Beta(df = Poly_List[[p]]@data,d_mat = TrsprtNet_CDmatList[[p]],
                     type = "rad_orig_prob")

tmp2 <- Est_Beta(df = Poly_List[[p]]@data,d_mat = TrsprtNet_CDmatList[[p]],
                     type = "rad_ext_prob_a0.5")

tmp3 <- Est_Beta(df = Poly_List[[p]]@data,d_mat = TrsprtNet_CDmatList[[p]],
                     type = "rad_ext_prob_a2")

## inspect separate plots
tmp1[[1]]
tmp2[[1]]
tmp3[[1]]

### compare fitted curves
rbind(tmp1[[3]],tmp2[[3]],tmp3[[3]])




```
  
Sociopolitical Administration
--power function decay
--should not have the precipitous falloff with cost-distance of the exponential model @2-3 hrs bc the logistical constraints of administration have more to do with the influence of rival settlements (Intervening opportunities) than physical costs -- particularly at the distances being considered here
--likewise, should not have the delayed falloff with distance at intermediate scales because closer settlements should not necessarily be weighted towards each other as compared to the influence of attractiveness
--at very small scales, the relation is a given
--this should lead to sharper boundaries along mutual-attractiveness isotones rather than gradual cost-distance gradients
--the power function's monotonic log-log relation nicely captures this comparative invariance of institutional relations to distance 
--parameterized to rad_ext_prob_a0.5 because this is the most linear log-log decay, achieving the greatest R2 margin over 

Agricultural Flows
--sharp exponential decay = rad_ext_prob_a2
-due to logistical constraints of staple transport + storage + ubiquitous supply and demand
-at short distances there should be dampened penalty because of cost-benefit -- if a surplus must be produced, then it must be transported some distance -- the closer the better

Socioeconomic Flows
-orig transport model
-Intervening opportunities
-empirically proven for longer distance flows, not insensitive to shorter distance flows
-dominated by scale effects
  
```{r, "compare radiation model distance decay across periods", message=FALSE, warning=FALSE}

tmp1 <- Est_Beta(df = Poly_List[[5]]@data,d_mat = TrsprtNet_CDmatList[[5]],
                     type = "rad_orig_prob")

tmp2 <- Est_Beta(df = Poly_List[[5]]@data,d_mat = TrsprtNet_CDmatList[[5]],
                     type = "rad_ext_prob_a0.5")

tmp3 <- Est_Beta(df = Poly_List[[5]]@data,d_mat = TrsprtNet_CDmatList[[5]],
                     type = "rad_ext_prob_a2")



tmp1 <- Est_Beta(df = Poly_List[[5]]@data,d_mat = TrsprtNet_CDmatList[[5]],
                     type = "rad_ext_prob_a2")

tmp2 <- Est_Beta(df = Poly_List[[7]]@data,d_mat = TrsprtNet_CDmatList[[7]],
                     type = "rad_ext_prob_a2")

tmp3 <- Est_Beta(df = Poly_List[[9]]@data,d_mat = TrsprtNet_CDmatList[[9]],
                     type = "rad_ext_prob_a2")

tmp4 <- Est_Beta(df = Poly_List[[11]]@data,d_mat = TrsprtNet_CDmatList[[11]],
                     type = "rad_ext_prob_a2")


```



## script estimating gravity model flows

--SpInt_EstFlows.R
taking beta function params
peeples/moin/rhill_wilson_algebraic retail model
network stats + network outputs as with Radiation_EstFlows

--SpInt.MapPlot.R
edges aggregated to symmetrical for plotting
custom node size variable
scatterplot plots dist decay beta function OR gam for transpot model
short bottom panel = equation + model info (passed from SpInt_EstFlows.R)
  
loop over each metric by period and output flow dimension
--add node stats to main data
--save nets and sflines as lists --> RDS
  
  
  
  
  
  
  
  
  
  
  
```{r, "radiation model GAM for Dist Decay", eval=FALSE, echo=F, message=FALSE, warning=FALSE}
df = Poly_List[[5]]@data
var = "Population.s2"
d_mat = TrsprtNet_CDmatList[[5]]
xc=Poly_List[[5]]@data$East
yc=Poly_List[[5]]@data$North
crsc=26914

rad_orig_prob = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=F,scale="none", 
                          commuters="none",outputs ="sflines")
rad_ext_prob_a0.5 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc, extended=T, scale="none", alpha=0.5,
                          commuters="none",outputs ="sflines")
rad_ext_prob_a2 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc, extended=T, scale="none", alpha=2,
                          commuters="none",outputs ="sflines")


```
  
```{r}
df <- rad_orig_prob[[1]]
df2 <- df[df$P > 0, ]
df2$Log_P <- log(df2$P)
df2$Log_r_ij <- log(df2$r_ij)

gam_model <- gam(Log_P ~ s(Log_r_ij), data = df2, method = "REML")

gratia::draw(gam_model, residuals=T)

summary(gam_model)

gam.check(gam_model)

gratia::appraise(gam_model)

```

  
```{r}
df <- rad_orig_prob[[1]]
df2 <- df[df$P > 0, ]
df2$Log_P <- log(df2$P)
df2$Log_r_ij <- log(df2$r_ij)

power_model <- lm(Log_P ~ Log_r_ij, data = df2)

ggPredict(power_model,point=T,se=TRUE,interactive=F) + geom_line(size=1.2, color="red") 

summary(power_model)

ggplot2::autoplot(power_model)

```
  
  
  
  
```{r}
df <- rad_orig_prob[[1]]
df2 <- df[df$P > 0, ]
df2$Log_P <- log(df2$P)
df2$Log_r_ij <- log(df2$r_ij)


W = 0.27^(1:nrow(df2))
exp_model <- lm(Log_P ~ r_ij, data = df2, weights=W)

ggPredict(exp_model,point=T,se=TRUE,interactive=F, weights=W) + geom_line(size=1.2, color="red") #+ scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)), labels = trans_format("log", math_format(e^.x)))

summary(exp_model)

ggplot2::autoplot(exp_model)

```
  
```{r}
df = Poly_List[[5]]@data
var = "Population.s2"
d_mat = TrsprtNet_CDmatList[[5]]
xc=Poly_List[[5]]@data$East
yc=Poly_List[[5]]@data$North
crsc=26914

rad_orig_prob = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc,extended=F,scale="none", 
                          commuters="none",outputs ="sflines")
rad_ext_prob_a0.5 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc, extended=T, scale="none", alpha=0.5,
                          commuters="none",outputs ="sflines")
rad_ext_prob_a2 = Radiation_EstFlows(df=df,var=var,d_mat=d_mat,xcoords=xc,ycoords=yc,
                          crs_coords=crsc, extended=T, scale="none", alpha=2,
                          commuters="none",outputs ="sflines")

df <- rad_orig_prob[[1]]
df2 <- df[df$P > 0, ]
df2$Log_P <- log(df2$P)
df2$Log_r_ij <- log(df2$r_ij)

################

gam_model <- gam(Log_P ~ s(Log_r_ij), data = df2, method = "REML")

gratia::draw(gam_model, residuals=T)

summary(gam_model)

gam.check(gam_model)

gratia::appraise(gam_model)

#############

power_model <- lm(Log_P ~ Log_r_ij, data = df2)
#power_model <- glm(P ~ Log_r_ij, data = df2, family = gaussian(link = 'log'))

ggPredict(power_model,point=T,se=TRUE,interactive=F) + geom_line(size=1.2, color="red") 
#ggPredict(power_model,point=T,se=TRUE,interactive=F) + geom_line(size=1.2, color="red") + scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)), labels = trans_format("log", math_format(e^.x)))

summary(power_model)
with(summary(exp_model), 1 - deviance/null.deviance)

ggplot2::autoplot(power_model)

#################
#exp_model <- lm(Log_P ~ r_ij, data = df2)
#W = 0.00001^(1:nrow(df2))
#exp_model <- lm(P ~ r_ij, family = gaussian(link = 'log'), data = df2, weights=W)
#exp_model <- stats:nls()

exp_model <- glm(P ~ r_ij, family = gaussian(link = 'log'), data = df2)
#equation: P = Intercept*exp(x*b)
#estimated equation: log(P) = log(Intercept) + r_ij*b
#reported intercept is log-transformed

ggPredict(exp_model,point=T,se=TRUE,interactive=F) + geom_line(size=1.2, color="red") +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)), labels = trans_format("log", math_format(e^.x)))+ 
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)), labels = trans_format("log", math_format(e^.x)))

summary(exp_model)
s=summary(exp_model)

with(summary(exp_model), 1 - deviance/null.deviance)

#ggplot2::autoplot(exp_model)

plot(df2$r_ij,df2$Log_P)
lines(df2$r_ij,log(exp_model$fitted.values),col="red")

plot(log(df2$r_ij),df2$Log_P)
lines(log(df2$r_ij),log(exp_model$fitted.values),col="red")

##################

nn=500
Log_x = seq(min(df2$Log_r_ij),max(df2$Log_r_ij),length.out = nn)
x = exp(Log_x)

GAM_y = as.numeric(predict.gam(gam_model,data.frame(Log_r_ij=Log_x)))
GAM_se = (predict.gam(gam_model,data.frame(Log_r_ij=Log_x),se.fit	=T)$se.fit)
GAM_CIh =  GAM_y + (qnorm(0.975)*GAM_se)
GAM_CIl =  GAM_y - (qnorm(0.975)*GAM_se)

Power_y = as.numeric(predict(power_model,data.frame(Log_r_ij=Log_x)))
Power_se = (predict(power_model,data.frame(Log_r_ij=Log_x),se.fit	=T)$se.fit)
Power_CIh =  Power_y + (qnorm(0.975)*Power_se)
Power_CIl =  Power_y - (qnorm(0.975)*Power_se)

#EXP_y = (s$coefficients[1])+(s$coefficients[2]*x)
#EXP_y = log(1/(1+exp(-(s$coefficients[2]*x+s$coefficients[1]))))
  #as.numeric(predict(exp_model,data.frame(r_ij=x))))

EXP_y = (as.numeric(predict(exp_model,data.frame(r_ij=x))))
EXP_se = (predict(exp_model,data.frame(r_ij=x),se.fit	=T)$se.fit)
EXP_CIh =  EXP_y + (qnorm(0.975)*EXP_se)
EXP_CIl =  EXP_y - (qnorm(0.975)*EXP_se)


pltmod = data.frame(Log_X = c(Log_x,Log_x,Log_x),
                    Model = c(rep("Exponential",nn),rep("Power",nn),rep("GAM",nn)),
                    Predict = c(EXP_y, Power_y, GAM_y),
                    CI95_h = c(EXP_CIh,Power_CIh,GAM_CIh),
                    CI95_l = c(EXP_CIl,Power_CIl,GAM_CIl))

ggplot() + geom_point(data=df2, aes(y=Log_P, x=Log_r_ij)) +
  geom_line(data=pltmod, aes(x=Log_X, y=Predict, color=Model), size=1.2)+
  geom_ribbon(data=pltmod, aes(x = Log_X, ymin = CI95_l, ymax = CI95_h, fill=Model), alpha = 0.2)+
  


## Turn results into
#### display tables for ggplot
#### output tables for df

x = seq(min(df2$r_ij),max(df2$r_ij),length.out = 500)


b <- getViz(gam_model)
o <- plot( sm(b, 1) )+l_fitLine()
o+p2

p1 = gratia::draw(gam_model, residuals=T)
p2 = ggPredict(power_model,point=T,se=TRUE,interactive=F) + geom_line(size=1.2, color="red") 

p1+
```
  

  
  
  
  
  
  
  






```{r, "compare radiation model results w/ different params", eval=FALSE, echo=F, message=FALSE, warning=FALSE}


ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "thistle1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))

hist(log(test$sfpts_netstats$Rad_centr_indeg))

fit_power_law(test$sfpts_netstats$Rad_centr_indeg)

ggplot(data = test$sfpts_netstats,aes(x = Population.s2, y = Rad_centr_totdeg)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Settlement Population", y = "Weighted Degree Centrality (in and out)",
       title = "Total Degree Centrality on Population: LF SBOM (400-200 BC)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))

##########################################

test$sflines$mn <- test$sflines$m+test$sflines$n
ggplot(data = test$sflines, aes(x = r_ij, y = Tij, color=mn, alpha=mn)) +
  geom_point(size=2) + 
  geom_smooth(method = "gam", formula = y~s(x,k=7), color="darkblue", fill="turquoise1")+
  scale_color_viridis(option = "turbo", begin = 0.60,name=expression('m'[i]+'n'[j]))+
  scale_alpha_continuous(range = c(0.30, 0.9), guide="none")+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Log Transport Network Cost Distance (hrs)", y = "Log Interaction Flow (T_ij)"
       #title = "Interaction Flows on Cost Distance: LF SBOM (400-200 BC)",
       #subtitle = "Scale Invariant Original Model with Commuters as Population"
       ) +
  theme_grey()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12),
        panel.grid.major = element_line(colour = "black"),
        panel.grid.minor = element_line(colour = "grey45"),
        panel.border = element_rect(color = "black", fill = NA),
        panel.background = element_rect(fill = "grey65"),
        legend.justification=c(0.5,0.5), legend.position=c(0.15,0.25), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid'))


#############################################



test$sflines$Log_Tij <- log(test$sflines$Tij)
sflines2 <- test$sflines[test$sflines$Log_Tij > 2,]
ggp_map <- ggplot() +  geom_stars(data = Hillshade.s)+
  scale_fill_gradientn(colours = c("turquoise3", "black", "gray60"), 
               values = scales::rescale(c(-9999, -161, 254)), guide="none")+
  geom_sf(data = CatchLims.sf, color="black", size=1, alpha = 0) +
  ggnewscale::new_scale_fill()+
  geom_sf(data = sflines2, mapping=aes(color=Log_Tij, alpha=Log_Tij), size=1) +
  scale_color_viridis(option = "turbo", begin = 0.5, na.value = NA, name = expression('logT'[ij])) +
  scale_alpha_continuous(range = c(0.25, 1), guide="none") +
  #geom_sf(data = Catch.sf, color="black", size=0.3, alpha = 0) +
  
  geom_sf(data=test$sfpts_netstats, mapping=aes(size=Population.s2), shape=21, fill = "darkblue", color="black", stroke = 1, alpha=1)+
  scale_size(range=c(1,6), name="Population")+
  #guides(alpha="none", fill = guide_legend(order = 1, override.aes = list(size = 3,nrow=3)),
  #       size = guide_legend(order = 2, override.aes = list(nrow=4)))+
  #labs(title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
  #     subtitle = "Scale Invariant Original Model with Commuters as Population")+
  coord_sf(datum = sf::st_crs(26914)) +
  xlim(484500,529378)+ylim(2106800,2150500)+
  theme_void() + 
  #labs(x = "Easting", y = "Northing")+
  theme(#legend.position="left", 
        legend.justification=c(0.5,0.5), legend.position=c(0.165,0.32), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')
        #plot.title = element_text(hjust = 0.5, face="bold", size=16),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=16)
        )

ggpmap<-ggsave("LF_RadiationMap.png", plot = ggp_map, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5.5,   units = "in",  dpi = 1000)

sfpts_netstats <- cbind(test$sfpts_netstats,Poly_List[[5]]@data)
x=st_drop_geometry(sfpts_netstats[,c(1,110:115,124,127:128,111:112)])

xx=as.matrix(1-dist(x[,-1],upper=T,method="manhattan"),ncol=ncol(x),nrow=nrow(x))

sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("from"="AggSite"))
sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("to"="AggSite"))
sflines2=sflines2 %>% mutate(rPert_sim = scales::rescale(abs(rPert.x - rPert.y),to=c(1,0)),
                        rPert0_sim = scales::rescale(abs(rPert0.x - rPert0.y),to=c(1,0)),
                        rPert2_sim = scales::rescale(abs(rPert2.x - rPert2.y),to=c(1,0)),
                        Abs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        LogAbs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        Pop_sim = scales::rescale(abs(m - n), to=c(1,0))) %>% 
  rowwise() %>% 
  mutate(Avg_Pert_sim = mean(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Min_Pert_sim = min(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Max_Pert_sim = max(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Med_Pert_sim = median(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         sd_Pert_sim = sd(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T)) %>% ungroup()
#3:5,9:12;;;13:22;;;24:34
x=st_drop_geometry(sflines2[,c(3:5,11,13:22)])

pairs.panels(x,
            gap = 0,
            pch=21)

plot(sfpts_netstats["OccuTime"])
```
p + stat_function(fun = LF) + xlim(250,266) +
    scale_y_continuous(trans = log_trans(), 
                         breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x)))



```{r}
test = Radiation_EstFlows(df = Poly_List[[9]]@data,
                       var = "Population.s2",
                       d_mat = TrsprtNet_CDmatList[[9]], 
                       xcoords = Poly_List[[9]]@data$East,
                       ycoords = Poly_List[[9]]@data$North,
                       crs_coords = 26914,
                       extended = F, #T
                       alpha = 1.2,
                       scale = "invariant", #c("invariant", "variant", "none")
                       commuters = "var", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "igraph", "sflines", "sfpts_netstats"))#, "sfnetwork"

ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "thistle1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: Classic SBOM (AD 100-550)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))

hist(log(test$sfpts_netstats$Rad_centr_indeg))

fit_power_law(test$sfpts_netstats$Rad_centr_indeg)

ggplot(data = test$sfpts_netstats,aes(x = Population.s2, y = Rad_centr_totdeg)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Settlement Population", y = "Weighted Degree Centrality (in and out)",
       title = "Total Degree Centrality on Population: CL SBOM (AD 100-550)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))


test$sflines$mn <- test$sflines$m+test$sflines$n
ggplt <- ggplot(data = test$sflines, aes(x = r_ij, y = Tij, color=mn, alpha=mn)) +
  geom_point(size=2) + 
  geom_smooth(method = "gam", formula = y~s(x,k=7), color="darkblue", fill="turquoise1")+
  scale_color_viridis(option = "turbo", begin = 0.60,name=expression('m'[i]+'n'[j]))+
  scale_alpha_continuous(range = c(0.30, 0.9), guide="none")+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  
  labs(x = "Log Transport Network Cost Distance (hrs)", y = "Log Interaction Flow (T_ij)"
       #title = "Interaction Flows on Cost Distance: LF SBOM (400-200 BC)",
       #subtitle = "Scale Invariant Original Model with Commuters as Population"
       ) +
  theme_grey()+
  theme(#plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.margin = margin(1.75, 0.5, 1.25, 0, "in"),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=14, face="bold"),
        axis.title.y = element_text(color="black", size=14, face="bold"),
        axis.text.y = element_text(color="black", size=14),
        axis.text.x = element_text(color="black", size=14),
        panel.grid.major = element_line(colour = "black"),
        panel.grid.minor = element_line(colour = "grey45"),
        panel.border = element_rect(color = "black", fill = NA),
        panel.background = element_rect(fill = "grey65"),
        legend.justification=c(0.5,0.5), legend.position=c(0.15,0.25), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=13),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid'))

ggpmap<-ggsave("CL_RadDistDecayPlot.png", plot = ggplt, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5,   units = "in",  dpi = 1000)

test$sflines$Log_Tij <- log(test$sflines$Tij)
sflines2 <- test$sflines[test$sflines$Log_Tij > 2,]

ggp_map <- ggplot() +  geom_stars(data = Hillshade.s)+
  scale_fill_gradientn(colours = c("turquoise3", "black", "gray60"), 
               values = scales::rescale(c(-9999, -161, 254)), guide="none")+
  geom_sf(data = CatchLims.sf, color="black", size=1, alpha = 0) +
  ggnewscale::new_scale_fill()+
  geom_sf(data = sflines2, mapping=aes(color=Log_Tij, alpha=Log_Tij), size=1) +
  scale_color_viridis(option = "turbo", begin = 0.6, na.value = NA, name = expression('logT'[ij])) +
  scale_alpha_continuous(range = c(0.25, 1), guide="none") +
  #geom_sf(data = Catch.sf, color="black", size=0.3, alpha = 0) +
  
  geom_sf(data=test$sfpts_netstats, mapping=aes(size=Population.s2), shape=21, fill = "darkblue", color="black", stroke = 1, alpha=1)+
  scale_size(range=c(1,6), name="Population")+
  guides(color = guide_colorbar(order = 1), size = guide_legend(order = 2))+
  #labs(title = "Radiation Model Interaction Flows: Classic Period SBOM (AD 100-550)",
  #     subtitle = "Scale Invariant Original Model with Commuters as Population")+
  coord_sf(datum = sf::st_crs(26914)) +
  xlim(484500,529378)+ylim(2106800,2150500)+
  theme_void() + 
  #labs(x = "Easting", y = "Northing")+
  theme(#legend.position="left", 
        legend.justification=c(0.5,0.5), legend.position=c(0.165,0.34), 
        legend.margin = margin(1, 4, 1, 4),
        plot.margin = margin(0, 0, 0, 0, "in"),#plot.margin = margin(0.2, 0, 0.3, 0.25, "in"),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')
        #plot.title = element_text(hjust = 0.5, face="bold", size=16),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=16)
        )

ggpmap<-ggsave("CL_RadiationMap.png", plot = ggp_map, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5.5,   units = "in",  dpi = 1000)

plot_row <- plot_grid(ggp_map, ggplt, align = "v", nrow = 1, rel_heights = c(1, 1/2),labels = c('A', 'B'), label_size=40, label_x = c(0.1,0.05), label_y = 0.9)
plot_row
title <- ggdraw() + draw_label("Radiation Model Interaction Flows: Classic Period SBOM (c. AD 100-550)",fontface = 'bold',hjust = 0.5, vjust=0.4, size=20 )

out <- plot_grid(title, plot_row,ncol = 1, rel_heights = c(0.04,1)) + 
          theme(plot.background = element_rect(fill = "white", colour = NA))

ggsave("CL_RadNetMapDistDecay.png", plot = out, device = "png", path = wd$figs, scale = 1, width = 12.5, height = 8.35,   units = "in",  dpi = 1250)



sfpts_netstats <- cbind(test$sfpts_netstats,Poly_List[[9]]@data)
x=st_drop_geometry(sfpts_netstats[,c(1,110:115,124,127:128,111:112)])

xx=as.matrix(1-dist(x[,-1],upper=T,method="manhattan"),ncol=ncol(x),nrow=nrow(x))

sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("from"="AggSite"))
sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("to"="AggSite"))
sflines2=sflines2 %>% mutate(rPert_sim = scales::rescale(abs(rPert.x - rPert.y),to=c(1,0)),
                        rPert0_sim = scales::rescale(abs(rPert0.x - rPert0.y),to=c(1,0)),
                        rPert2_sim = scales::rescale(abs(rPert2.x - rPert2.y),to=c(1,0)),
                        Abs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        LogAbs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        Pop_sim = scales::rescale(abs(m - n), to=c(1,0))) %>% 
  rowwise() %>% 
  mutate(Avg_Pert_sim = mean(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Min_Pert_sim = min(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Max_Pert_sim = max(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Med_Pert_sim = median(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         sd_Pert_sim = sd(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T)) %>% ungroup()
#3:5,9:12;;;13:22;;;24:34
x=st_drop_geometry(sflines2[,c(3:5,11,13:22)])

pairs.panels(x,
            gap = 0,
            pch=21)

plot(sfpts_netstats["OccuTime"])
```




```{r}
test = Radiation_EstFlows(df = Poly_List[[13]]@data,
                       var = "Population.s2",
                       d_mat = TrsprtNet_CDmatList[[13]], 
                       xcoords = Poly_List[[13]]@data$East,
                       ycoords = Poly_List[[13]]@data$North,
                       crs_coords = 26914,
                       extended = F, #T
                       alpha = 1.2,
                       scale = "invariant", #c("invariant", "variant", "none")
                       commuters = "var", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "igraph", "sflines", "sfpts_netstats"))#, "sfnetwork"

ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "thistle1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: LT-AzI SBOM (AD 950-1200)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))

hist(log(test$sfpts_netstats$Rad_centr_indeg))

fit_power_law(test$sfpts_netstats$Rad_centr_indeg)

ggplot(data = test$sfpts_netstats,aes(x = Population.s2, y = Rad_centr_totdeg)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Settlement Population", y = "Weighted Degree Centrality (in and out)",
       title = "Total Degree Centrality on Population: LT-AzI SBOM (AD 950-1200)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))


ggplot(data = test$sflines,aes(x = r_ij, y = Tij)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Transport Net Cost Distance (hrs)", y = "Interaction Flow (T_ij)",
       title = "Interaction Flows on Cost Distance: LT-AzI SBOM (AD 950-1200)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))

test$sflines$Log_Tij <- log(test$sflines$Tij)
sflines2 <- test$sflines[test$sflines$Log_Tij > 2,]
ggp_map <- ggplot() +  geom_stars(data = Hillshade.s)+
  scale_fill_gradientn(colours = c("turquoise3", "black", "gray60"), 
               values = scales::rescale(c(-9999, -161, 254)), guide="none")+
  geom_sf(data = CatchLims.sf, color="black", size=1, alpha = 0) +
  ggnewscale::new_scale_fill()+
  geom_sf(data = sflines2, mapping=aes(color=Log_Tij, alpha=Log_Tij), size=1) +
  scale_color_viridis(option = "turbo", begin = 0.6, na.value = NA, name = expression('logT'[ij])) +
  scale_alpha_continuous(range = c(0.25, 1), guide="none") +
  #geom_sf(data = Catch.sf, color="black", size=0.3, alpha = 0) +
  
  geom_sf(data=test$sfpts_netstats, mapping=aes(size=Population.s2), shape=21, fill = "darkblue", color="black", stroke = 1, alpha=1)+
  scale_size(range=c(1,6), name="Population")+
  #guides(alpha="none", fill = guide_legend(order = 1, override.aes = list(size = 3,nrow=3)),
  #       size = guide_legend(order = 2, override.aes = list(nrow=4)))+
  #labs(title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
  #     subtitle = "Scale Invariant Original Model with Commuters as Population")+
  coord_sf(datum = sf::st_crs(26914)) +
  xlim(484500,529378)+ylim(2106800,2150500)+
  theme_void() + 
  #labs(x = "Easting", y = "Northing")+
  theme(#legend.position="left", 
        legend.justification=c(0.5,0.5), legend.position=c(0.165,0.32), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')
        #plot.title = element_text(hjust = 0.5, face="bold", size=16),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=16)
        )

ggpmap<-ggsave("LTAzI_RadiationMap.png", plot = ggp_map, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5.5,   units = "in",  dpi = 1000)

sfpts_netstats <- cbind(test$sfpts_netstats,Poly_List[[13]]@data)
x=st_drop_geometry(sfpts_netstats[,c(1,110:115,124,127:128,111:112)])

xx=as.matrix(1-dist(x[,-1],upper=T,method="manhattan"),ncol=ncol(x),nrow=nrow(x))

sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("from"="AggSite"))
sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("to"="AggSite"))
sflines2=sflines2 %>% mutate(rPert_sim = scales::rescale(abs(rPert.x - rPert.y),to=c(1,0)),
                        rPert0_sim = scales::rescale(abs(rPert0.x - rPert0.y),to=c(1,0)),
                        rPert2_sim = scales::rescale(abs(rPert2.x - rPert2.y),to=c(1,0)),
                        Abs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        LogAbs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        Pop_sim = scales::rescale(abs(m - n), to=c(1,0))) %>% 
  rowwise() %>% 
  mutate(Avg_Pert_sim = mean(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Min_Pert_sim = min(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Max_Pert_sim = max(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Med_Pert_sim = median(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         sd_Pert_sim = sd(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T)) %>% ungroup()
#3:5,9:12;;;13:22;;;24:34
x=st_drop_geometry(sflines2[,c(3:5,11,13:22)])

pairs.panels(x,
            gap = 0,
            pch=21)

plot(sfpts_netstats["OccuTime"])
```

```{r}
test = Radiation_EstFlows(df = Poly_List[[11]]@data,
                       var = "Population.s2",
                       d_mat = TrsprtNet_CDmatList[[11]], 
                       xcoords = Poly_List[[11]]@data$East,
                       ycoords = Poly_List[[11]]@data$North,
                       crs_coords = 26914,
                       extended = F, #T
                       alpha = 1.2,
                       scale = "invariant", #c("invariant", "variant", "none")
                       commuters = "var", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "igraph", "sflines", "sfpts_netstats"))#, "sfnetwork"

ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "thistle1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: ET SBOM (AD 650-850)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))

hist(log(test$sfpts_netstats$Rad_centr_indeg))

fit_power_law(test$sfpts_netstats$Rad_centr_indeg)

ggplot(data = test$sfpts_netstats,aes(x = Population.s2, y = Rad_centr_totdeg)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Settlement Population", y = "Weighted Degree Centrality (in and out)",
       title = "Total Degree Centrality on Population: ET SBOM (AD 650-850)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))


ggplot(data = test$sflines,aes(x = r_ij, y = Tij)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Transport Net Cost Distance (hrs)", y = "Interaction Flow (T_ij)",
       title = "Interaction Flows on Cost Distance: ET SBOM (AD 650-850)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))

test$sflines$Log_Tij <- log(test$sflines$Tij)
sflines2 <- test$sflines[test$sflines$Log_Tij > 2,]
ggp_map <- ggplot() +  geom_stars(data = Hillshade.s)+
  scale_fill_gradientn(colours = c("turquoise3", "black", "gray60"), 
               values = scales::rescale(c(-9999, -161, 254)), guide="none")+
  geom_sf(data = CatchLims.sf, color="black", size=1, alpha = 0) +
  ggnewscale::new_scale_fill()+
  geom_sf(data = sflines2, mapping=aes(color=Log_Tij, alpha=Log_Tij), size=1) +
  scale_color_viridis(option = "turbo", begin = 0.6, na.value = NA, name = expression('logT'[ij])) +
  scale_alpha_continuous(range = c(0.25, 1), guide="none") +
  #geom_sf(data = Catch.sf, color="black", size=0.3, alpha = 0) +
  
  geom_sf(data=test$sfpts_netstats, mapping=aes(size=Population.s2), shape=21, fill = "darkblue", color="black", stroke = 1, alpha=1)+
  scale_size(range=c(1,6), name="Population")+
  #guides(alpha="none", fill = guide_legend(order = 1, override.aes = list(size = 3,nrow=3)),
  #       size = guide_legend(order = 2, override.aes = list(nrow=4)))+
  #labs(title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
  #     subtitle = "Scale Invariant Original Model with Commuters as Population")+
  coord_sf(datum = sf::st_crs(26914)) +
  xlim(484500,529378)+ylim(2106800,2150500)+
  theme_void() + 
  #labs(x = "Easting", y = "Northing")+
  theme(#legend.position="left", 
        legend.justification=c(0.5,0.5), legend.position=c(0.165,0.32), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')
        #plot.title = element_text(hjust = 0.5, face="bold", size=16),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=16)
        )

ggpmap<-ggsave("ET_RadiationMap.png", plot = ggp_map, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5.5,   units = "in",  dpi = 1000)

sfpts_netstats <- cbind(test$sfpts_netstats,Poly_List[[11]]@data)
x=st_drop_geometry(sfpts_netstats[,c(1,110:115,124,127:128,111:112)])

xx=as.matrix(1-dist(x[,-1],upper=T,method="manhattan"),ncol=ncol(x),nrow=nrow(x))

sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("from"="AggSite"))
sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("to"="AggSite"))
sflines2=sflines2 %>% mutate(rPert_sim = scales::rescale(abs(rPert.x - rPert.y),to=c(1,0)),
                        rPert0_sim = scales::rescale(abs(rPert0.x - rPert0.y),to=c(1,0)),
                        rPert2_sim = scales::rescale(abs(rPert2.x - rPert2.y),to=c(1,0)),
                        Abs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        LogAbs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        Pop_sim = scales::rescale(abs(m - n), to=c(1,0))) %>% 
  rowwise() %>% 
  mutate(Avg_Pert_sim = mean(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Min_Pert_sim = min(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Max_Pert_sim = max(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Med_Pert_sim = median(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         sd_Pert_sim = sd(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T)) %>% ungroup()
#3:5,9:12;;;13:22;;;24:34
x=st_drop_geometry(sflines2[,c(3:5,11,13:22)])

pairs.panels(x,
            gap = 0,
            pch=21)

plot(sfpts_netstats["OccuTime"])
```


```{r}
test = Radiation_EstFlows(df = Poly_List[[16]]@data,
                       var = "Population.s2",
                       d_mat = TrsprtNet_CDmatList[[16]], 
                       xcoords = Poly_List[[16]]@data$East,
                       ycoords = Poly_List[[16]]@data$North,
                       crs_coords = 26914,
                       extended = T, #T
                       alpha = 0.5,
                       scale = "invariant", #c("invariant", "variant", "none")
                       commuters = "var", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "igraph", "sflines", "sfpts_netstats"))#, "sfnetwork"

ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "thistle1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: EA_LA SBOM (AD 1350-1475)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))

hist(log(test$sfpts_netstats$Rad_centr_indeg))

fit_power_law(test$sfpts_netstats$Rad_centr_indeg)

ggplot(data = test$sfpts_netstats,aes(x = Population.s2, y = Rad_centr_totdeg)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Settlement Population", y = "Weighted Degree Centrality (in and out)",
       title = "Total Degree Centrality on Population: EA_LA SBOM (AD 1350-1475)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))


ggplot(data = test$sflines,aes(x = r_ij, y = Tij)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Transport Net Cost Distance (hrs)", y = "Interaction Flow (T_ij)",
       title = "Interaction Flows on Cost Distance: EA_LA SBOM (AD 1350-1475)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))


test$sflines$Log_Tij <- log(test$sflines$Tij)
sflines2 <- test$sflines[test$sflines$Log_Tij > 2,]
ggp_map <- ggplot() +  geom_stars(data = Hillshade.s)+
  scale_fill_gradientn(colours = c("turquoise3", "black", "gray60"), 
               values = scales::rescale(c(-9999, -161, 254)), guide="none")+
  geom_sf(data = CatchLims.sf, color="black", size=1, alpha = 0) +
  ggnewscale::new_scale_fill()+
  geom_sf(data = sflines2, mapping=aes(color=Log_Tij, alpha=Log_Tij), size=1) +
  scale_color_viridis(option = "turbo", begin = 0.6, na.value = NA, name = expression('logT'[ij])) +
  scale_alpha_continuous(range = c(0.25, 1), guide="none") +
  #geom_sf(data = Catch.sf, color="black", size=0.3, alpha = 0) +
  
  geom_sf(data=test$sfpts_netstats, mapping=aes(size=Population.s2), shape=21, fill = "darkblue", color="black", stroke = 1, alpha=1)+
  scale_size(range=c(1,6), name="Population")+
  #guides(alpha="none", fill = guide_legend(order = 1, override.aes = list(size = 3,nrow=3)),
  #       size = guide_legend(order = 2, override.aes = list(nrow=4)))+
  #labs(title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
  #     subtitle = "Scale Invariant Original Model with Commuters as Population")+
  coord_sf(datum = sf::st_crs(26914)) +
  xlim(484500,529378)+ylim(2106800,2150500)+
  theme_void() + 
  #labs(x = "Easting", y = "Northing")+
  theme(#legend.position="left", 
        legend.justification=c(0.5,0.5), legend.position=c(0.165,0.32), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')
        #plot.title = element_text(hjust = 0.5, face="bold", size=16),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=16)
        )

ggpmap<-ggsave("EA_LA_RadiationMap.png", plot = ggp_map, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5.5,   units = "in",  dpi = 1000)

sfpts_netstats <- cbind(test$sfpts_netstats,Poly_List[[16]]@data)
x=st_drop_geometry(sfpts_netstats[,c(1,110:115,124,127:128,111:112)])

xx=as.matrix(1-dist(x[,-1],upper=T,method="manhattan"),ncol=ncol(x),nrow=nrow(x))

sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("from"="AggSite"))
sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("to"="AggSite"))
sflines2=sflines2 %>% mutate(rPert_sim = scales::rescale(abs(rPert.x - rPert.y),to=c(1,0)),
                        rPert0_sim = scales::rescale(abs(rPert0.x - rPert0.y),to=c(1,0)),
                        rPert2_sim = scales::rescale(abs(rPert2.x - rPert2.y),to=c(1,0)),
                        Abs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        LogAbs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        Pop_sim = scales::rescale(abs(m - n), to=c(1,0))) %>% 
  rowwise() %>% 
  mutate(Avg_Pert_sim = mean(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Min_Pert_sim = min(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Max_Pert_sim = max(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Med_Pert_sim = median(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         sd_Pert_sim = sd(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T)) %>% ungroup()
#3:5,9:12;;;13:22;;;24:34
x=st_drop_geometry(sflines2[,c(3:5,11,13:22)])

pairs.panels(x,
            gap = 0,
            pch=21)

plot(sfpts_netstats["OccuTime"])
```









```{r}
test = Radiation_EstFlows(df = Poly_List[[12]]@data,
                       var = "Population.s2",
                       d_mat = TrsprtNet_CDmatList[[12]], 
                       xcoords = Poly_List[[12]]@data$East,
                       ycoords = Poly_List[[12]]@data$North,
                       crs_coords = 26914,
                       extended = F, #T
                       alpha = 0.5,
                       scale = "invariant", #c("invariant", "variant", "none")
                       commuters = "var", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "igraph", "sflines", "sfpts_netstats"))#, "sfnetwork"

ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "thistle1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: ET LTAzI SBOM (AD 850-950)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))

hist(log(test$sfpts_netstats$Rad_centr_indeg))

fit_power_law(test$sfpts_netstats$Rad_centr_indeg)

ggplot(data = test$sfpts_netstats,aes(x = Population.s2, y = Rad_centr_totdeg)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~x,method.args = list(family = gaussian()))+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Settlement Population", y = "Weighted Degree Centrality (in and out)",
       title = "Total Degree Centrality on Population: ET LTAzI SBOM (AD 850-950)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))

###########################
ggplot(data = test$sflines,aes(x = r_ij, y = Tij)) +
  geom_point(size=2) +
  geom_smooth(method = "glm", formula = y~ exp(x) + exp(m) + exp(n),method.args = list(family = poisson()), 
              color="blue", fill="deepskyblue", size=1.3)+
  geom_smooth(method = "gam", formula = y ~ s(x), color="red2", fill="salmon", 
              size=1, linetype = "twodash", alpha=0.4)+
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  labs(x = "Log Transport Network Cost Distance (hrs)", y = "Log Interaction Flow (T_ij)",
       title = "Interaction Flows on Cost Distance: ET LTAzI SBOM (AD 850-950)",
       subtitle = "Scale Invariant Original Model with Commuters as Population") +
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=12))
######################################

test$sflines$Log_Tij <- log(test$sflines$Tij)
sflines2 <- test$sflines[test$sflines$Log_Tij > 2,]
ggp_map <- ggplot() +  geom_stars(data = Hillshade.s)+
  scale_fill_gradientn(colours = c("turquoise3", "black", "gray60"), 
               values = scales::rescale(c(-9999, -161, 254)), guide="none")+
  geom_sf(data = CatchLims.sf, color="black", size=1, alpha = 0) +
  ggnewscale::new_scale_fill()+
  geom_sf(data = sflines2, mapping=aes(color=Log_Tij, alpha=Log_Tij), size=1) +
  scale_color_viridis(option = "turbo", begin = 0.6, na.value = NA, name = expression('logT'[ij])) +
  scale_alpha_continuous(range = c(0.25, 1), guide="none") +
  #geom_sf(data = Catch.sf, color="black", size=0.3, alpha = 0) +
  
  geom_sf(data=test$sfpts_netstats, mapping=aes(size=Population.s2), shape=21, fill = "darkblue", color="black", stroke = 1, alpha=1)+
  scale_size(range=c(1,6), name="Population")+
  #guides(alpha="none", fill = guide_legend(order = 1, override.aes = list(size = 3,nrow=3)),
  #       size = guide_legend(order = 2, override.aes = list(nrow=4)))+
  #labs(title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
  #     subtitle = "Scale Invariant Original Model with Commuters as Population")+
  coord_sf(datum = sf::st_crs(26914)) +
  xlim(484500,529378)+ylim(2106800,2150500)+
  theme_void() + 
  #labs(x = "Easting", y = "Northing")+
  theme(#legend.position="left", 
        legend.justification=c(0.5,0.5), legend.position=c(0.165,0.32), 
        legend.margin = margin(1, 4, 1, 4),
        legend.spacing.y = unit(0.1,"line"),legend.spacing.x = unit(0.55,"line"), 
        legend.text=element_text(size=11),legend.title=element_text(size=16),
        legend.key = element_rect(colour = "transparent", fill = "white"), 
        legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')
        #plot.title = element_text(hjust = 0.5, face="bold", size=16),
        #plot.subtitle = element_text(hjust = 0.5, face="bold", size=16)
        )

ggpmap<-ggsave("ET_LTAzI_RadiationMap.png", plot = ggp_map, device = "png", path = wd$figs, scale = 1, width = 5.5, height = 5.5,   units = "in",  dpi = 1000)

sfpts_netstats <- cbind(test$sfpts_netstats,Poly_List[[12]]@data)
x=st_drop_geometry(sfpts_netstats[,c(1,110:115,124,127:128,111:112)])

xx=as.matrix(1-dist(x[,-1],upper=T,method="manhattan"),ncol=ncol(x),nrow=nrow(x))

sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("from"="AggSite"))
sflines2=left_join(sflines2, x[,c("AggSite","rPert","Abs_rPert","LogAbs_rPert","rPert0","rPert2")], by=c("to"="AggSite"))
sflines2=sflines2 %>% mutate(rPert_sim = scales::rescale(abs(rPert.x - rPert.y),to=c(1,0)),
                        rPert0_sim = scales::rescale(abs(rPert0.x - rPert0.y),to=c(1,0)),
                        rPert2_sim = scales::rescale(abs(rPert2.x - rPert2.y),to=c(1,0)),
                        Abs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        LogAbs_rPert_sim = scales::rescale(abs(Abs_rPert.x - Abs_rPert.y), to=c(1,0)),
                        Pop_sim = scales::rescale(abs(m - n), to=c(1,0))) %>% 
  rowwise() %>% 
  mutate(Avg_Pert_sim = mean(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Min_Pert_sim = min(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Max_Pert_sim = max(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         Med_Pert_sim = median(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T),
         sd_Pert_sim = sd(c(rPert_sim, rPert0_sim, rPert2_sim, Abs_rPert_sim, LogAbs_rPert_sim), na.rm=T)) %>% ungroup()
#3:5,9:12;;;13:22;;;24:34
x=st_drop_geometry(sflines2[,c(3:5,11,13:22)])

pairs.panels(x,
            gap = 0,
            pch=21)

plot(sfpts_netstats["OccuTime"])
```













































```{r}
test = Radiation_EstFlows(df = Poly_List[[5]]@data,
                       var = "Population.s2",
                       d_mat = CD.mats[[5]], 
                       xcoords = Poly_List[[5]]@data$East,
                       ycoords = Poly_List[[5]]@data$North,
                       crs_coords = 26914,
                       extended = F, #T
                       alpha = 1.2,
                       scale = "none", #c("invariant", "variant", "none")
                       commuters = "none", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "sflines", "sfpts_netstats"))#, "sfnetwork"

ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "lightgreen", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
       subtitle = "Scale Invariant Original Model Conditional Probabilities") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))


```


```{r}
test = Radiation_EstFlows(df = Poly_List[[5]]@data,
                       var = "Population.s2",
                       d_mat = CD.mats[[5]], 
                       xcoords = Poly_List[[5]]@data$East,
                       ycoords = Poly_List[[5]]@data$North,
                       crs_coords = 26914,
                       extended = T, #T
                       alpha = 0.2,
                       scale = "variant", #c("invariant", "variant", "none")
                       commuters = "var", #c("var", "input", "none")
                       Ti_input = NULL,
                       outputs = c("adjmat", "sflines", "sfpts_netstats"))#, "sfnetwork"


ggplot(test$sflines, aes(Tij)) +
  geom_histogram(color = "#000000", fill = "khaki1", bins = 20) +
  labs(x = "Interaction Flows (T_ij)", y = "Frequency",
       title = "Radiation Model Interaction Flows: Late Formative SBOM (400-200 BC)",
       subtitle = "Scale Variant Extended Model with Commuters as Population & alpha=0.2") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks(n = 10, "log", function(x) exp(x)),
                     labels = label_number(accuracy =0.001))+
  theme_bw()+
  theme(plot.title=element_text(hjust = 0.5, size=14, face="bold"),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size=12),
        axis.title.x = element_text(color="black", size=12, face="bold"),
        axis.title.y = element_text(color="black", size=12, face="bold"),
        axis.text.y = element_text(color="black", size=12),
        axis.text.x = element_text(color="black", size=9, angle=20))


```



```{r}
add = modeldf %>% select(from,to,s,n_s,orig_invar_P, orig_invar_Tij,orig_var_P, orig_var_Tij)
colnames(add) <- c("O","D","s","n_s","orig_invar_P", "orig_invar_Tij","orig_var_P", "orig_var_Tij")

pts_sf = st_as_sf(Pts_List[[5]]) %>% 
              dplyr::select(AggSite,AggID,Period,PeriodNum,Population.s2,
                            UrbanPop.s2,rPert,Abs_rPert,rPert0,rPert2,Persist,Found,OccuTime,
                            OccuInertia,PopPressure,PopPressureNW,AGPot.tot,EZ.avg,
                            SetHierLevel,AGPot.avg,LQ_UrbPop,FLQ_UrbPop,spGini_Pop,
                            spGini_UrbOccuInertia,centr_clos,centr_eig,ScalResid) %>% 
  mutate(Grow = ifelse(rPert > 0, 1, 0),
               Grow = factor(Grow, levels=c(0,1)))
                                                   

d_mat = TrsprtNet_CDmatList[[5]]

od_sim = si_to_od_dmat(origins = pts_sf, destinations = pts_sf, dmat = d_mat)

od_sim = od_sim %>% left_join(add, by=c("O","D"))

### An unconstrained SIM
#A simplistic SIM - in this case an inverse power distance decay function (negative exponential is another commonly used decay function) - can be created just based on the distance between points:

si_power = function(d, beta) d^beta

od_calculated = si_calculate(
  od_sim,
  fun = si_power,
  d = distance,
  beta = -3.8
  )
plot(od_calculated["interaction"], logz = TRUE)

#This approach, ignoring all variables at the level of trip origins and destinations, results in flow estimates with no units.
#Before learning how to run constrained SIMs, let's scale the result by the total flow and see how far we are from reality, just focussing on the interzonal OD pairs:

od_calculated_interzonal = od_calculated %>%filter(O != D) 
  
scale_factor = sum(od_calculated_interzonal$orig_invar_Tij, na.rm=T) /
  sum(od_calculated_interzonal$interaction, na.rm=T)
od_calculated_interzonal = od_calculated_interzonal %>% 
  mutate(interaction_scaled = interaction * scale_factor)

od_calculated_interzonal %>% 
  ggplot() +
  geom_point(aes(orig_invar_Tij, interaction_scaled))
cor(od_calculated_interzonal$orig_invar_Tij, od_calculated_interzonal$interaction_scaled)^2

#The results show that a simple unconstrained model, without any parameter fitting, can explain less than 20% of the variability in flows.
#We can do better!

od_calculated_interzonal<- od_calculated_interzonal %>% 
  mutate(decay = distance^-3.8) %>% 
  mutate(decay = decay * (sum(orig_invar_Tij) / sum(decay)))
cor(od_calculated_interzonal$orig_invar_Tij, od_calculated_interzonal$decay)^2
  ggplot() +
  geom_point(od_calculated_interzonal, mapping=aes(distance, orig_invar_Tij)) +
  geom_line(od_calculated_interzonal, mapping=aes(distance, decay), colour = "red") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x)))
  
  od_constrained_p = si_calculate(
  od_calculated_interzonal,
  fun = si_power,
  d = distance,
  beta = -0.9,
  constraint_production = origin_Population.s2
  )
  cor(od_constrained_p$orig_invar_Tij, od_constrained_p$interaction)^2
od_constrained_p %>% 
  ggplot() +
  geom_point(aes(orig_invar_Tij, interaction))

#An advantage of the flow data used in this example is that we already know the interaction. (This raises the question of why a SIM is needed, answer: to test our models and demonstrate the techniques.)

#We can do this using the nls() function as follows:#

library(minpack.lm)
f = orig_invar_Tij ~ a * (distance)^b
m = nlsLM(
  formula = f,
  data = od_calculated_interzonal,
  )
m



od_calculated_interzonal %>% 
  mutate(decay = distance^-0.614) %>% 
  mutate(decay = decay * 16.539) %>% 
  ggplot() +
  geom_point(aes(distance, orig_invar_Tij)) +
  geom_line(aes(distance, decay), colour = "red") +
  scale_x_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x))) +
  scale_y_continuous(trans = log_trans(), breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x)))

od_pred_const = si_predict(od_calculated_interzonal, model = m,
  constraint_production = origin_Population.s2)
cor(od_pred_const$orig_invar_Tij, od_pred_const$interaction)^2

```















p + stat_function(fun = LF) + xlim(250,266) +
    scale_y_continuous(trans = log_trans(), 
                         breaks = trans_breaks("log", function(x) exp(x)),
                         labels = trans_format("log", math_format(e^.x)))

of the number of job opportunities between the source and the destination on the job selection


-\frac{m_i}{M}

### Dimensional Proxies for "Total Commuters" T_i

```{r, 'Proxies for Radiation Model T_i', message=FALSE, warning=FALSE}

```


## Rihll-Wilson Retail Model

```{r}

```




# Recombining and Reorganizing the Data

```{r, 'Recombining the Data', message=FALSE, warning=FALSE}
# Convert lists of period-wise sites/catchments to single SPDF objects
All_Agg_SitePoly <-  do.call(rbind, Poly_List)
All_Agg_CatchPoly <- do.call(rbind, Catch_List)

# variables from site data that needs transfer over to catchment areas
colz1 = setdiff(colnames(All_Agg_SitePoly@data),colnames(All_Agg_CatchPoly@data))
# variables from catchment areas that needs transfer over to site data
colz2 = setdiff(colnames(All_Agg_CatchPoly@data),colnames(All_Agg_SitePoly@data))

#reorder the data to match
All_Agg_SitePoly <- All_Agg_SitePoly[order(All_Agg_SitePoly$AggSite),]
All_Agg_CatchPoly <- All_Agg_CatchPoly[order(All_Agg_CatchPoly$AggSite),]

#check to see that the two datasets are in the right order
#identical(All_Agg_SitePoly@data$AggSite, All_Agg_CatchPoly@data$AggSite)

# Site data to catchment areas
Site_to_Catch <- All_Agg_SitePoly@data %>% select(!!!syms(colz1))
All_Agg_CatchPoly@data <- cbind(All_Agg_CatchPoly@data,Site_to_Catch)

# catchment area data to sites
Catch_to_Site <- All_Agg_CatchPoly@data %>% select(!!!syms(colz2))
All_Agg_SitePoly@data <- cbind(All_Agg_SitePoly@data,Catch_to_Site)

#Reorganize the data

ordering <- c(
  #ID VARIABLES
      "AggSite","AggID","Site","East","North","SurvReg","Number","CerPhase","Period", 
      "PeriodType","PeriodLength","PeriodNum","PeriodBegin","PeriodEnd", 
      "OccSeqLoc","OccSeqLoc.Sites","SubOccSeqLoc","SubOccSeqLoc.Sites",
      "ComponentNum", "ComponentSites",
  #CHRONOLOGICAL VARIABLES
      "PeriodInterval", "PeriodBegin", "PeriodBegin.era", "PeriodMidpoint", 
      "PeriodMidpoint.era", "PeriodEnd", "PeriodEnd.era", "PeriodLength",
  #OCCUPATION VARIABLES (COUNTS)
      "Occ.EF","Occ.EF_MF","Occ.MF","Occ.MF_LF","Occ.LF","Occ.LF_TF",
      "Occ.TF","Occ.TF_CL","Occ.CL","Occ.CL_ET","Occ.ET","Occ.ET_LTAzI", 
      "Occ.LTAzI","Occ.LTAzI_EA","Occ.EA","Occ.EA_LA","Occ.LA","Occ.TOT",
  #SUBOCCUPATION VARIABLES (COUNTS)
      "SubOcc.EF","SubOcc.EF_MF","SubOcc.MF","SubOcc.MF_LF","SubOcc.LF",
      "SubOcc.LF_TF","SubOcc.TF","SubOcc.TF_CL","SubOcc.CL","SubOcc.CL_ET",
      "SubOcc.ET","SubOcc.ET_LTAzI","SubOcc.LTAzI","SubOcc.LTAzI_EA",
      "SubOcc.EA","SubOcc.EA_LA","SubOcc.LA","SubOcc.TOT",
  #SITE AREA AND OCCUPATIONAL DENSITY VARS
      "Area_ha","Perim_m2","SherdDens","Tot.Assemb","FwOvlp.Assemb", 
      "BwOvlp.Assemb", "Net.Assemb",
  #STEP #2 DEMOGRAPHIC VARIABLES
      "Population.s2","Log_Population.s2", "ApportAssemb", "PopDens.s2",
      "UrbanScale.s2", "UrbanPop.s2","RuralPop.s2", "PctUrban.s2","PctRural.s2",
      "Prior", "Observed", "MeanOccuProb", 
  #STEP #2 DEMOGRAPHIC RATES
      "Pct_deltaPop12", "Pct_deltaPop01", "r12_Pert", "r01_Pert",
      "r23_Pert", "rPert", "rPert0", "rPert2", 
      "Pct_UrbdeltaPop12", "Pct_UrbdeltaPop01", "Urb_r12_Pert", "Urb_r01_Pert",
      "Urb_r23_Pert", "Urb_rPert", "Urb_rPert0", "Urb_rPert2",
      "Abs_rPert","RS_rPert","LogRS_rPert","LogAbs_rPert","Q.rPert","Q.Abs_rPert",
      "Q.RS_rPert","Q.LogRS_rPert","Q.LogAbs_rPert","Urb_Abs_rPert",
      "Urb_RS_rPert","Urb_LogRS_rPert","Urb_LogAbs_rPert","Q.Urb_rPert","Q.Urb_Abs_rPert",
      "Q.Urb_RS_rPert","Q.Urb_LogRS_rPert","Q.Urb_LogAbs_rPert",
      "Qp.rPert","Qp.Abs_rPert","Qp.RS_rPert","Qp.LogRS_rPert","Qp.LogAbs_rPert",
  #STEP #1 DEMOGRAPHIC VARIABLES
      "Population.s1","PopDens.s1","UrbanScale.s1","UrbanPop.s1","RuralPop.s1", 
      "PctUrban.s1","PctRural.s1",
  #CONTINUITY VARIABLES
      "AreaBwCont","AreaFwCont","PopBwCont","PopFwCont","FwOvlp.Sites",
      "FwOvlp.Area","FwOvlp.Pop","BwOvlp.Sites","BwOvlp.Area","BwOvlp.Pop",
  #PERSISTENCE VARIABLES
      "Found","FoundInit","Abandon","Persist","DewarType",
      "OccuTime","OccuInertia","UrbOccuTime","UrbOccuInertia",
  #STEP #4 TRANSPORT NETWORK VARIABLES
      "TranspDens.pct", "TranspDens.rank","centr_deg","centr_btw","centr_eig",
      "centr_clos","centr_hrmo","centr_hub","centr_auth","centr_pgrk",
      "centr_deg_n","centr_btw_n","centr_eig_n","centr_clos_n","centr_hrmo_n",
      "centr_hub_n","centr_auth_n","centr_avg","trans_loc","trans_locavg",
      "density","connectiv","trans_glob","cntrlz_deg","cntrlz_btw","cntrlz_eig",
      "cntrlz_clo","cntrlz_hub","cntrlz_auth","cntrlz_deg_n","cntrlz_btw_n",
      "cntrlz_eig_n","cntrlz_clo_n","cntrlz_hub_n","cntrlz_auth_n","cntrlz_avg",
  #STEP #4 CATCHMENT AREA AND POP DENSITY VARIABLES
      "Catchment_ha", "CatchmentBeyond_ha", "Catch_Popdens", 
      "Catch_Popdens_PropMax","Catch_Popdens_Rank","CatchB_Popdens",
      "CatchB_Popdens_PropMax", "CatchB_Popdens_Rank", 
  #STEP #5 CATCHMENT ENVIRONMENT/TOPOGRAPHY VARIABLES
      "NPP.tot","NPP.avg","EZ.avg","EZ.sd","TRI.tot","TRI.avg","IrrigPot.tot",
      "IrrigPot.avg","WetAgPot.tot","WetAgPot.avg","IntnsCost.tot",
      "IntnsCost.avg","IntnsCostNW.tot","IntnsCostNW.avg","AGPot.tot",
      "AGPot.avg","AGPotNW.tot","AGPotNW.avg","PopPressure","PopPressureNW",
      "ErosionPot.tot","ErosionPot.avg", 
  #STEP #6 SETTLEMENT HIERARCHY DEMOG VARS
      "SetHierLevel","ScalResid","ScalSlope","ScalInt","Pop_PropMax","Pop_Rank",
      "UrbanPop_PropMax","UrbanPop_Rank","PopDens_PropMax","PopDens_Rank",
      "UrbanScale_PropMax","UrbanScale_Rank",
  #STEP #6 SETTLEMENT HIERARCHY/DEMOG LOCATION QUOTIENTS
      "LQ_UrbPop","FLQ_UrbPop","LQ_UrbOccuTime","FLQ_UrbOccuTime","LQ_UrbOccuInertia",
      "FLQ_UrbOccuInertia","LQ_PopFwCont","LQ_PopBwCont","LQ_AreaFwCont","LQ_AreaBwCont",
      #"LQ_Pct_UrbdeltaPop12","FLQ_Pct_UrbdeltaPop12","LQ_PopDens",
      #"FLQ_PopDens","LQ_Catch_Popdens","FLQ_Catch_Popdens","LQ_Urb_Abs_rPert",
      #"FLQ_Urb_Abs_rPert","LQ_Q.Urb_rPert","FLQ_Q.Urb_rPert",
  #STEP #6 SETTLEMENT HIERARCHY/DEMOG SPATIAL GINIS
      "spGini_Pop","spGini_UrbPop","spGini_OccuTime","spGini_UrbOccuTime",
      "spGini_OccuInertia","spGini_UrbOccuInertia","spGini_Pct_deltaPop12",
      'spGini_Pct_UrbdeltaPop12',"spGini_Area_ha","spGini_Catchment_ha",
      "spGini_Abs_rPert","spGini_Urb_Abs_rPert","spGini_Q.rPert","spGini_Q.Urb_rPert",
      "spGini_FwOvlp.Pop","spGini_BwOvlp.Pop","spGini_FwOvlp.Area","spGini_BwOvlp.Area",
      "spGini_PopPressure",
  #STEP #6 TRANSPORT NETWORK SPATIAL GINIS
      "spGini_centr_avg","spGini_centr_deg","spGini_centr_btw",
      "spGini_centr_eig","spGini_centr_clos","spGini_centr_hrmo","spGini_centr_hub",
      "spGini_centr_auth","spGini_centr_pgrk","spGini_trans_loc","spGini_SetHierLevel",
  #SURVEY METADATA
      "M_Sites","M_SiteCode","M_SiteName","M_FieldSite.Region",
      "M_FieldSite.Period","M_SurveyYearNumber","M_Supervisor","M_Map",
  #OLD tDAR BOM SURVEY VARIABLES
      "O_Elev","O_ElevMed","O_ElevMin","O_ElevMax","O_EZcode",
      "O_EnvironmentalZone","O_Soil","O_SoilMed","O_SoilMin","O_SoilMax",
      "O_Erosion","O_ErosionMed","O_ErosionMin","O_ErosionMax","O_ModernUse",
      "O_ModernSettlement","O_Rainfall","O_Area","O_MoundDomestic",
      "O_MoundCeremonial","O_MoundQuestionable","O_MoundTotal",
      "O_MoundRecorded","O_DMoundArea","O_Architecture","O_TerraceConfidence",
      "O_TerraceExtent","O_Sherd","O_SherdMed","O_SherdMin","O_SherdMax",
      "O_Rubble","O_RubbleMed","O_RubbleMin","O_RubbleMax","O_Population",
      "O_PopMin","O_PopMax","O_PopMethod","O_stcode","O_SiteType",
      "O_SubPeriod1","O_SubPeriod2","O_OccEF","O_OccMF","O_OccLF","O_OccTF",
      "O_OccCL","O_OccEC","O_OccMC","O_OccLC","O_OccET","O_OccLT","O_OccAZ",
      "O_OccEA","O_OccLA","O_OccTot","O_OccSeqLoc","O_SubOc1","O_SubOc2",
      "O_PdDupSite","O_Group","O_Comments") 

#Make sure everything is kosher
#setdiff(colnames(All_Agg_CatchPoly@data),ordering)
#setdiff(colnames(All_Agg_SitePoly@data),ordering)
#setdiff(ordering,colnames(All_Agg_CatchPoly@data))
#setdiff(ordering,colnames(All_Agg_SitePoly@data))

# Reorder the data for both sites and catchment areas
All_Agg_SitePoly@data <- All_Agg_SitePoly@data %>% select(!!!syms(ordering))
All_Agg_CatchPoly@data <- All_Agg_CatchPoly@data %>% select(!!!syms(ordering))
```


# Export Data for Script #8

```{r, 'Export Data for Step #8', message=FALSE,warning=FALSE}

#AggSite polygons
writeOGR(All_Agg_SitePoly, paste0(dir2,"SBOM_AggSitePoly7.gpkg"), "SBOM_AggSitePoly7", driver = "GPKG", overwrite_layer=TRUE)

#Catchment areas
writeOGR(All_Agg_CatchPoly, paste0(dir2,"SBOM_CatchPoly7.gpkg"), "SBOM_CatchPoly7", driver = "GPKG", overwrite_layer=TRUE)

```


# References
